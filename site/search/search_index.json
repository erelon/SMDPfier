{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SMDPfier Documentation","text":"<p>Welcome to SMDPfier, a Gymnasium wrapper that enables Semi-Markov Decision Process (SMDP) behavior in reinforcement learning environments through Options with simple, natural time semantics.</p>"},{"location":"#overview","title":"Overview","text":"<p>SMDPfier transforms any Gymnasium environment into an SMDP by allowing agents to execute Options (sequences of primitive actions) where each primitive action = 1 tick of time, enabling natural SMDP discounting.</p> <p>\ud83c\udfaf Key Insight: Each primitive action = 1 tick. Option duration = number of actions executed. Simple and natural.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd17 Flexible Options: Static sequences or dynamic discovery via callable</li> <li>\u26a1 Two Interfaces: Index-based (Discrete actions) or direct Option passing  </li> <li>\u23f1\ufe0f Simple Time Semantics: Each primitive action = 1 tick, duration = k_exec</li> <li>\ud83c\udfad Action Masking: Support for discrete action availability</li> <li>\ud83d\udcca Rich Info: Comprehensive execution metadata in <code>info[\"smdp\"]</code></li> <li>\ud83d\udee1\ufe0f Error Handling: Detailed validation and runtime errors</li> <li>\ud83d\udd04 Continuous Actions: Full support for continuous action spaces</li> <li>\ud83c\udfb2 Built-in Defaults: Ready-to-use option generators and reward aggregators</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#index-interface-recommended-for-rl","title":"Index Interface (Recommended for RL)","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\n\n# Create environment and define options\nenv = gym.make(\"CartPole-v1\")\noptions = [\n    Option(actions=[0, 0, 1], name=\"left-left-right\"),   # 3 actions = 3 ticks\n    Option(actions=[1, 1, 0], name=\"right-right-left\"),  # 3 actions = 3 ticks\n    Option(actions=[0, 1], name=\"left-right\"),           # 2 actions = 2 ticks\n]\n\n# Wrap with SMDPfier\nsmdp_env = SMDPfier(\n    env,\n    options_provider=options,       # Static options list\n    action_interface=\"index\",       # Discrete(3) action space\n    max_options=len(options)\n)\n\n# Use like any Gym environment\nobs, info = smdp_env.reset()\nobs, reward, term, trunc, info = smdp_env.step(0)  # Execute first option\n\n# Access SMDP metadata\nsmdp = info[\"smdp\"]\nprint(f\"Option '{smdp['option']['name']}' executed {smdp['k_exec']} steps\")\nprint(f\"Duration: {smdp['duration']} ticks (= k_exec)\")\nprint(f\"Per-step rewards: {smdp['rewards']}\")\n\n# Apply SMDP discounting\ngamma = 0.99\ndiscounted_reward = reward * (gamma ** smdp['duration'])\n</code></pre>"},{"location":"#direct-interface-intuitive","title":"Direct Interface (Intuitive)","text":"<pre><code># Pass Option objects directly\nsmdp_env = SMDPfier(env, options_provider=options, action_interface=\"direct\")\n\n# Execute with Option object\nobs, reward, term, trunc, info = smdp_env.step(options[0])\n</code></pre>"},{"location":"#core-concepts","title":"Core Concepts","text":""},{"location":"#options","title":"Options","text":"<p>Options are sequences of primitive actions that are executed atomically:</p> <pre><code># An option with 3 primitive actions\noption = Option(\n    actions=[0, 1, 0],           # Action sequence\n    name=\"left-right-left\",      # Human-readable name\n    meta={\"strategy\": \"zigzag\"}  # Optional metadata\n)\n</code></pre>"},{"location":"#time-semantics-v020","title":"Time Semantics (v0.2.0+)","text":"<p>Simple and natural: - Each primitive action = 1 tick of time - Option duration = k_exec (number of primitive actions executed) - If option completes: <code>duration = len(option.actions)</code> - If terminated early: <code>duration &lt; len(option.actions)</code></p> <p>Example: <pre><code>option = Option([0, 1, 0], \"three-action-option\")  # 3 actions\n\n# If it completes normally: duration = 3 ticks\n# If episode terminates after 2 actions: duration = 2 ticks\n</code></pre></p>"},{"location":"#smdp-discounting","title":"SMDP Discounting","text":"<p>Standard MDP: <code>\u03b3^{1}</code> per primitive step SMDP: <code>\u03b3^{k}</code> where k = option duration</p> <pre><code># MDP: Each primitive step discounts by \u03b3\nmdp_return = r\u2081 + \u03b3\u00b9\u00b7r\u2082 + \u03b3\u00b2\u00b7r\u2083 + \u03b3\u00b3\u00b7r\u2084\n\n# SMDP: Each option discounts by \u03b3^{duration}\n# Options with lengths [3, 2, 4]:  \nsmdp_return = r\u2081 + \u03b3\u00b3\u00b7r\u2082 + \u03b3\u2075\u00b7r\u2083 + \u03b3\u2079\u00b7r\u2084\n#                   \u2191      \u2191       \u2191\n#                   3    3+2    3+2+4\n</code></pre>"},{"location":"#action-interfaces","title":"Action Interfaces","text":"<p>SMDPfier provides two ways to select options:</p> <p>Index Interface (Recommended for RL) <pre><code>action_interface=\"index\"  \n# Creates Discrete(max_options) action space\n# Use integer indices: env.step(0), env.step(1), etc.\n</code></pre></p> <p>Direct Interface (Intuitive) <pre><code>action_interface=\"direct\"\n# Pass Option objects directly: env.step(option)\n</code></pre></p>"},{"location":"#smdp-info-payload","title":"SMDP Info Payload","text":"<p>Every step returns comprehensive metadata in <code>info[\"smdp\"]</code>:</p> <pre><code>{\n    \"option\": {\n        \"id\": \"abc123...\",           # Stable hash-based ID  \n        \"name\": \"left-right-left\",   # Human-readable name\n        \"len\": 3,                    # Number of actions\n        \"meta\": {}                   # User metadata\n    },\n    \"k_exec\": 3,                     # Steps actually executed\n    \"duration\": 3,                   # Duration in ticks (= k_exec)\n    \"rewards\": [1.0, 1.0, 1.0],     # Per-step rewards\n    \"terminated_early\": False,       # Episode ended during option?\n    \"action_mask\": [1, 1, 0],       # Available options (index interface only)\n    \"num_dropped\": 0                 # Dropped options (index interface only)\n}\n</code></pre> <p>See the API Reference for complete details.</p>"},{"location":"#documentation-guide","title":"Documentation Guide","text":"Section Focus When to Read API Reference Complete SMDPfier API Setting up your wrapper Durations Guide Duration = k_exec, SMDP discounting Understanding time semantics Index vs Direct Interface comparison Choosing action interface Masking &amp; Precheck Action constraints Handling invalid actions Error Handling Debugging failed options Troubleshooting FAQ Common questions Quick answers Migration from 0.1.x Upgrading to v0.2.0 Updating existing code"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<p>\ud83d\ude80 New to SMDPfier? Start with the Quick Start above and FAQ.</p> <p>\ud83e\udd16 Building an RL agent? See Index Interface and Durations.</p> <p>\ud83d\udd27 Need custom behavior? Check API Reference and examples/.</p> <p>\u2753 Something not working? Try Error Handling and FAQ.</p> <p>\u2b06\ufe0f Upgrading from 0.1.x? See Migration Guide.</p> <p>Next: API Reference | Examples: ../examples/</p> <pre><code>pip install smdpfier\n</code></pre> <p>For development: <pre><code>git clone https://github.com/smdpfier/smdpfier.git\ncd smdpfier\npip install -e .[dev]\n</code></pre></p>"},{"location":"#examples","title":"Examples","text":""},{"location":"#cartpole-with-static-options-index-interface","title":"CartPole with Static Options (Index Interface)","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import Option, SMDPfier\nfrom smdpfier.defaults import ConstantOptionDuration, sum_rewards\n\n# Create base environment\nenv = gym.make(\"CartPole-v1\")\n\n# Define static options\nstatic_options = [\n    Option([0, 0, 1], \"left-left-right\", meta={\"category\": \"mixed\"}),\n    Option([1, 1, 0], \"right-right-left\", meta={\"category\": \"mixed\"}), \n    Option([0, 0, 0], \"left-triple\", meta={\"category\": \"directional\"}),\n    Option([1, 1, 1], \"right-triple\", meta={\"category\": \"directional\"}),\n]\n\n# Create SMDPfier with index interface\nsmdp_env = SMDPfier(\n    env,\n    options_provider=static_options,\n    duration_fn=ConstantOptionDuration(10),  # 10 ticks per option\n    reward_agg=sum_rewards,\n    action_interface=\"index\",\n    max_options=len(static_options),\n)\n\n# Execute\nobs, info = smdp_env.reset(seed=42)\nobs, reward, terminated, truncated, info = smdp_env.step(0)\n\n# Check results\nsmdp_info = info[\"smdp\"]\nprint(f\"Executed option: {smdp_info['option']['name']}\")\nprint(f\"Steps: {smdp_info['k_exec']}/{smdp_info['option']['len']}\")\nprint(f\"Duration: {smdp_info['duration_exec']} ticks\")\n</code></pre>"},{"location":"#taxi-with-dynamic-options-masking-index-interface","title":"Taxi with Dynamic Options &amp; Masking (Index Interface)","text":"<pre><code>import gymnasium as gym  \nfrom smdpfier import Option, SMDPfier\nfrom smdpfier.defaults import RandomActionDuration, mean_rewards\n\ndef create_taxi_options(obs, info):\n    \"\"\"Dynamic option provider based on current state.\"\"\"\n    return [\n        Option([0], \"south\", meta={\"type\": \"primitive\"}),\n        Option([1], \"north\", meta={\"type\": \"primitive\"}),\n        Option([2], \"east\", meta={\"type\": \"primitive\"}),\n        Option([3], \"west\", meta={\"type\": \"primitive\"}),\n        Option([4], \"pickup\", meta={\"type\": \"primitive\"}),\n        Option([5], \"dropoff\", meta={\"type\": \"primitive\"}),\n        # Navigation sequences\n        Option([0, 2], \"south-east\", meta={\"type\": \"navigation\"}),\n        Option([1, 3], \"north-west\", meta={\"type\": \"navigation\"}),\n    ]\n\ndef taxi_availability_function(obs):\n    \"\"\"Restrict certain actions based on state.\"\"\"\n    # Movement always available\n    available = [0, 1, 2, 3]\n    # Conditionally add pickup/dropoff\n    if (obs + 42) % 10 &lt; 7:  # Pseudo-random condition\n        available.append(4)  # pickup\n    if (obs + 17) % 10 &lt; 6:\n        available.append(5)  # dropoff\n    return available\n\n# Create SMDPfier with masking\nenv = gym.make(\"Taxi-v3\")\nsmdp_env = SMDPfier(\n    env,\n    options_provider=create_taxi_options,\n    duration_fn=RandomActionDuration(3, 8),\n    reward_agg=mean_rewards,\n    action_interface=\"index\",\n    max_options=12,\n    availability_fn=taxi_availability_function,\n    precheck=True,\n)\n\nobs, info = smdp_env.reset(seed=42)\n\n# Check masking\nmask = info[\"action_mask\"]\navailable_options = [i for i, avail in enumerate(mask) if avail]\nprint(f\"Available options: {available_options}\")\n\nobs, reward, terminated, truncated, info = smdp_env.step(available_options[0])\nprint(f\"Mean reward: {reward:.3f}\")\n</code></pre>"},{"location":"#pendulum-with-continuous-actions-direct-interface","title":"Pendulum with Continuous Actions (Direct Interface)","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import Option, SMDPfier  \nfrom smdpfier.defaults import ConstantActionDuration, discounted_sum\n\n# Create continuous action options\ncontinuous_options = [\n    Option([[1.0], [-1.0], [1.0], [-1.0]], \"oscillate-high\", \n           meta={\"category\": \"oscillation\"}),\n    Option([[0.5], [-0.5], [0.5]], \"oscillate-medium\",\n           meta={\"category\": \"oscillation\"}), \n    Option([[0.0], [0.0], [0.0]], \"hold-steady\",\n           meta={\"category\": \"stabilization\"}),\n]\n\n# Create SMDPfier with direct interface  \nenv = gym.make(\"Pendulum-v1\")\nsmdp_env = SMDPfier(\n    env,\n    options_provider=continuous_options,\n    duration_fn=ConstantActionDuration(4),  # 4 ticks per action\n    reward_agg=discounted_sum,\n    action_interface=\"direct\",\n)\n\nobs, info = smdp_env.reset(seed=42)\n\n# Execute by passing Option objects directly\noption_to_execute = continuous_options[0]  # oscillate-high\nobs, reward, terminated, truncated, info = smdp_env.step(option_to_execute)\n\nsmdp_info = info[\"smdp\"]\nprint(f\"Executed {smdp_info['k_exec']} actions\")\nprint(f\"Total duration: {smdp_info['duration_exec']} ticks\")\nprint(f\"Discounted reward: {reward:.3f}\")\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Usage Guide - Interface comparison and examples</li> <li>Durations - Understanding duration metadata and SMDP discounting</li> <li>FAQ - Common questions and troubleshooting</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete reference for SMDPfier classes, functions, and configurations.</p>"},{"location":"api/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"api/#basic-smdpfier-setup","title":"Basic SMDPfier Setup","text":"<pre><code>from smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import sum_rewards\nimport gymnasium as gym\n\n# Basic setup with static options\nenv = gym.make(\"CartPole-v1\")\noptions = [\n    Option([0, 1], \"left-right\"),     # 2 actions = 2 ticks\n    Option([1, 0], \"right-left\")      # 2 actions = 2 ticks\n]\n\nsmdp_env = SMDPfier(\n    env,\n    options_provider=options,\n    action_interface=\"index\",\n    max_options=len(options)\n)\n</code></pre>"},{"location":"api/#dynamic-options-with-built-in-generators","title":"Dynamic Options with Built-in Generators","text":"<pre><code>from smdpfier.defaults.options import RandomStaticLen\n\nsmdp_env = SMDPfier(\n    env,\n    options_provider=RandomStaticLen(length=3, num_options=8),\n    action_interface=\"index\",\n    max_options=8\n)\n</code></pre>"},{"location":"api/#core-classes","title":"Core Classes","text":""},{"location":"api/#smdpfier","title":"SMDPfier","text":"<p>Primary wrapper class that transforms any Gymnasium environment into an SMDP.</p> <pre><code>class SMDPfier(gym.Wrapper):\n    def __init__(\n        self,\n        env: gym.Env,\n        *,\n        options_provider: Callable[[Any, dict], list[Option]] | Sequence[Option],\n        reward_agg: Callable[[list[float]], float] = sum_rewards,\n        action_interface: Literal[\"index\", \"direct\"] = \"index\",\n        max_options: int | None = None,\n        availability_fn: Optional[Callable[[Any], Iterable[int]]] = None,\n        precheck: bool = False,\n        rng_seed: int | None = None,\n    )\n</code></pre>"},{"location":"api/#parameters","title":"Parameters","text":"Parameter Type Required Default Description <code>env</code> <code>gym.Env</code> \u2705 - Base Gymnasium environment <code>options_provider</code> <code>Callable</code> or <code>Sequence[Option]</code> \u2705 - Static options or dynamic generator <code>reward_agg</code> <code>Callable</code> \u274c <code>sum_rewards</code> How to aggregate per-step rewards <code>action_interface</code> <code>\"index\"</code> or <code>\"direct\"</code> \u274c <code>\"index\"</code> Action selection interface <code>max_options</code> <code>int</code> or <code>None</code> \u274c <code>None</code> Max options (required for index interface) <code>availability_fn</code> <code>Callable</code> or <code>None</code> \u274c <code>None</code> Action masking function <code>precheck</code> <code>bool</code> \u274c <code>False</code> Validate options before execution <code>rng_seed</code> <code>int</code> or <code>None</code> \u274c <code>None</code> Random seed for reproducibility"},{"location":"api/#methods","title":"Methods","text":"<p><code>step(action: int | Option) -&gt; tuple[obs, reward, terminated, truncated, info]</code></p> <p>Execute an option in the environment.</p> <ul> <li>Index interface: <code>action</code> is integer index</li> <li>Direct interface: <code>action</code> is Option object</li> </ul> <p><code>reset(**kwargs) -&gt; tuple[obs, info]</code></p> <p>Reset the environment and return initial observation and info.</p> <p><code>close()</code></p> <p>Close the environment.</p>"},{"location":"api/#option","title":"Option","text":"<p>Represents a sequence of primitive actions with metadata.</p> <pre><code>class Option:\n    def __init__(\n        self,\n        actions: Sequence[Any],\n        name: str,\n        meta: dict | None = None\n    )\n</code></pre>"},{"location":"api/#parameters_1","title":"Parameters","text":"Parameter Type Required Description <code>actions</code> <code>Sequence[Any]</code> \u2705 Sequence of primitive actions <code>name</code> <code>str</code> \u2705 Human-readable option name <code>meta</code> <code>dict</code> or <code>None</code> \u274c Additional metadata"},{"location":"api/#properties","title":"Properties","text":"<ul> <li><code>actions</code>: The action sequence</li> <li><code>name</code>: Human-readable name</li> <li><code>meta</code>: User-defined metadata dictionary</li> <li><code>id</code>: Stable hash-based identifier (computed from actions + name)</li> </ul>"},{"location":"api/#examples","title":"Examples","text":"<pre><code># Discrete actions\noption1 = Option([0, 1, 0], \"left-right-left\")\n\n# Continuous actions\noption2 = Option([[-1.0], [0.5], [2.0]], \"continuous-sequence\")\n\n# With metadata\noption3 = Option(\n    actions=[0, 0, 1, 1], \n    name=\"double-pairs\",\n    meta={\"category\": \"symmetric\", \"difficulty\": \"easy\"}\n)\n\nprint(option1.id)  # Stable hash: \"a1b2c3...\"\n</code></pre>"},{"location":"api/#smdp-info-payload-structure","title":"SMDP Info Payload Structure","text":"<p>Every <code>step()</code> call returns comprehensive metadata in <code>info[\"smdp\"]</code>:</p> <pre><code>{\n    \"option\": {\n        \"id\": \"abc123...\",              # Stable hash-based ID\n        \"name\": \"left-right-left\",      # Human-readable name\n        \"len\": 3,                       # Number of primitive actions\n        \"meta\": {\"category\": \"test\"}    # User metadata (if any)\n    },\n    \"k_exec\": 3,                        # Primitive steps actually executed\n    \"duration\": 3,                      # Duration in ticks (= k_exec)\n    \"rewards\": [1.0, 1.0, 1.0],        # Per-step rewards\n    \"terminated_early\": False,          # Whether episode ended during option\n    \"action_mask\": [1, 1, 0, 1],       # Available option indices (index interface only)\n    \"num_dropped\": 0                    # Options dropped due to overflow (index interface only)\n}\n</code></pre>"},{"location":"api/#info-fields-detail","title":"Info Fields Detail","text":"Field Type Description <code>option.id</code> <code>str</code> Stable identifier (hash of actions + name) <code>option.name</code> <code>str</code> Human-readable option name <code>option.len</code> <code>int</code> Total number of primitive actions in option <code>option.meta</code> <code>dict</code> User-defined metadata <code>k_exec</code> <code>int</code> Number of primitive steps actually executed <code>duration</code> <code>int</code> Duration in ticks (always equals k_exec) <code>rewards</code> <code>list[float]</code> Per-primitive-step rewards <code>terminated_early</code> <code>bool</code> True if episode ended before option completed <code>action_mask</code> <code>list[int]</code> Binary mask of available options (index interface) <code>num_dropped</code> <code>int</code> Number of options dropped due to overflow (index interface)"},{"location":"api/#action-interfaces","title":"Action Interfaces","text":""},{"location":"api/#index-interface","title":"Index Interface","text":""},{"location":"api/#action-interfaces_1","title":"Action Interfaces","text":""},{"location":"api/#index-interface_1","title":"Index Interface","text":"<p>Transforms the action space to <code>Discrete(max_options)</code> where actions are integer indices.</p> <p>Configuration: <pre><code>env = SMDPfier(\n    base_env,\n    options_provider=options,\n    action_interface=\"index\",\n    max_options=len(options)  # Required\n)\n\n# Usage\naction = 1  # Select second option\nobs, reward, term, trunc, info = env.step(action)\n</code></pre></p> <p>Features: - Built-in action masking via <code>info[\"smdp\"][\"action_mask\"]</code> - Overflow handling for dynamic options - Seamless RL algorithm integration</p>"},{"location":"api/#direct-interface","title":"Direct Interface","text":"<p>Allows passing <code>Option</code> objects directly to <code>step()</code>.</p> <p>Configuration: <pre><code>env = SMDPfier(\n    base_env,\n    options_provider=options,\n    action_interface=\"direct\"\n    # No max_options needed\n)\n\n# Usage\noption = options[1]  # Select option object\nobs, reward, term, trunc, info = env.step(option)\n</code></pre></p> <p>Features: - Intuitive option selection - Full control over option choice - Works naturally with continuous actions</p>"},{"location":"api/#built-in-defaults","title":"Built-in Defaults","text":""},{"location":"api/#option-generators","title":"Option Generators","text":"<p><code>RandomStaticLen</code> - Generate random options with fixed length:</p> <pre><code>from smdpfier.defaults.options import RandomStaticLen\n\ngenerator = RandomStaticLen(\n    length=3,                    # Fixed option length (= 3 ticks)\n    action_space_size=4,         # Discrete action space size (auto-detected if None)\n    num_options=10,              # Number of options to generate\n    rng_seed=42                  # Random seed\n)\n</code></pre> <p><code>RandomVarLen</code> - Generate random options with variable length:</p> <pre><code>from smdpfier.defaults.options import RandomVarLen\n\ngenerator = RandomVarLen(\n    min_length=2,                # Minimum option length (= 2 ticks)\n    max_length=5,                # Maximum option length (= 5 ticks)\n    action_space_size=4,         # Discrete action space size\n    num_options=8,               # Number of options to generate\n    rng_seed=42                  # Random seed\n)\n</code></pre>"},{"location":"api/#reward-aggregation","title":"Reward Aggregation","text":"<pre><code>from smdpfier.defaults import sum_rewards, mean_rewards, discounted_sum\n\n# Sum all per-step rewards (default)\nreward_agg = sum_rewards\n\n# Average per-step rewards\nreward_agg = mean_rewards\n\n# Discount per-step rewards with \u03b3\nreward_agg = discounted_sum(gamma=0.99)\n</code></pre>"},{"location":"api/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"api/#static-options-with-index-interface","title":"Static Options with Index Interface","text":"<pre><code>options = [\n    Option([0, 1], \"left-right\"),                # 2 ticks\n    Option([1, 0], \"right-left\"),                # 2 ticks\n    Option([0, 0, 1], \"left-left-right\"),        # 3 ticks\n]\n\nenv = SMDPfier(\n    base_env,\n    options_provider=options,\n    action_interface=\"index\",\n    max_options=len(options)\n)\n</code></pre>"},{"location":"api/#dynamic-options-with-masking","title":"Dynamic Options with Masking","text":"<pre><code>def dynamic_generator(obs, info):\n    # Generate options based on current state\n    if obs[0] &gt; 0:\n        return [Option([0], \"left\"), Option([0, 0], \"double-left\")]\n    else:\n        return [Option([1], \"right\"), Option([1, 1], \"double-right\")]\n\ndef availability_mask(obs):\n    # Mask options based on state\n    return [0, 1] if obs[1] &gt; 0.5 else [0, 1]  # All available\n\nenv = SMDPfier(\n    base_env,\n    options_provider=dynamic_generator,\n    action_interface=\"index\",\n    max_options=5,\n    availability_fn=availability_mask\n)\n</code></pre>"},{"location":"api/#continuous-actions-with-direct-interface","title":"Continuous Actions with Direct Interface","text":"<pre><code>continuous_options = [\n    Option([[-1.0], [0.0]], \"left-center\"),            # 2 ticks\n    Option([[0.5], [1.0]], \"gentle-hard-right\"),       # 2 ticks\n    Option([[-2.0], [2.0], [0.0]], \"extreme-swing\"),   # 3 ticks\n]\n\nenv = SMDPfier(\n    gym.make(\"Pendulum-v1\"),\n    options_provider=continuous_options,\n    action_interface=\"direct\"\n)\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":"<p>SMDPfier provides detailed error context through specialized exceptions:</p> <pre><code>from smdpfier.errors import SMDPOptionValidationError, SMDPOptionExecutionError\n\ntry:\n    obs, reward, term, trunc, info = env.step(action)\nexcept SMDPOptionValidationError as e:\n    print(f\"Precheck failed for option '{e.option_name}' at step {e.failing_step_index}\")\n    print(f\"Action: {e.action_repr}, State: {e.short_obs_summary}\")\nexcept SMDPOptionExecutionError as e:\n    print(f\"Runtime error for option '{e.option_name}' at step {e.failing_step_index}\")\n    print(f\"Underlying error: {e.base_error}\")\n</code></pre> <p>See Error Handling for complete details.</p>"},{"location":"api/#custom-functions","title":"Custom Functions","text":""},{"location":"api/#custom-options-provider","title":"Custom Options Provider","text":"<pre><code>def custom_options_provider(obs, info):\n    \"\"\"Generate options based on observation and info.\"\"\"\n    # Access current state\n    position = obs[0]\n\n    # Access action space if needed\n    action_space = info.get(\"action_space\")\n\n    # Access action mask if available\n    action_mask = info.get(\"action_mask\")\n\n    # Generate options\n    options = []\n    if position &gt; 0:\n        options.append(Option([0, 0], \"strong-left\"))\n    if position &lt; 0:\n        options.append(Option([1, 1], \"strong-right\"))\n\n    return options\n</code></pre>"},{"location":"api/#custom-duration-function","title":"Custom Duration Function","text":"<pre><code>def custom_duration_fn(option, obs, info):\n    \"\"\"Compute duration based on option and state.\"\"\"\n    base_duration = len(option.actions) * 2\n\n    # State-dependent adjustment\n    if obs[0] &gt; 0.5:  # Far right position\n        return base_duration + 3  # Takes longer\n    else:\n        return base_duration\n\n# Can return scalar (int) or list (list[int])\ndef per_action_duration_fn(option, obs, info):\n    \"\"\"Return duration for each action.\"\"\"\n    durations = []\n    for action in option.actions:\n        if action == 0:  # Left action\n            durations.append(2)\n        else:  # Right action\n            durations.append(5)\n    return durations\n</code></pre>"},{"location":"api/#custom-availability-function","title":"Custom Availability Function","text":"<pre><code>def custom_availability_fn(obs):\n    \"\"\"Return available option indices based on state.\"\"\"\n    position, velocity = obs[0], obs[1]\n\n    available = []\n\n    # Always allow basic options\n    available.extend([0, 1])\n\n    # Complex options only when stable\n    if abs(velocity) &lt; 0.1:\n        available.extend([2, 3, 4])\n\n    return available\n</code></pre>"},{"location":"api/#performance-tips","title":"Performance Tips","text":""},{"location":"api/#efficient-option-generation","title":"Efficient Option Generation","text":"<pre><code># Pre-compute static options when possible\nstatic_options = [Option([0, 1], f\"option_{i}\") for i in range(10)]\n\n# Cache dynamic options when state doesn't change much\nclass CachedOptionsProvider:\n    def __init__(self):\n        self._cache = {}\n\n    def __call__(self, obs, info):\n        state_key = tuple(obs[:2])  # Use subset of observation as key\n        if state_key not in self._cache:\n            self._cache[state_key] = generate_options_for_state(obs)\n        return self._cache[state_key]\n</code></pre>"},{"location":"api/#memory-efficient-duration-functions","title":"Memory-Efficient Duration Functions","text":"<pre><code># Use generators for large option sets\ndef memory_efficient_duration_fn(option, obs, info):\n    # Compute duration on demand rather than storing\n    return len(option.actions) * compute_action_cost(obs)\n</code></pre>"},{"location":"api/#action-masking","title":"Action Masking","text":"<p>Action masking in SMDPfier is handled through the <code>availability_fn</code> parameter and works exclusively with the index interface. See the Masking and Precheck guide for comprehensive examples.</p> <pre><code>def availability_fn(obs):\n    \"\"\"Return list of available option indices.\"\"\"\n    # Return indices of valid options based on current state\n    return [0, 2, 3]  # Options 1 is masked out\n\nenv = SMDPfier(\n    base_env,\n    options_provider=options,\n    duration_fn=duration_fn,\n    action_interface=\"index\",\n    availability_fn=availability_fn\n)\n\n# Action mask appears in info\nobs, info = env.reset()\nmask = info[\"smdp\"][\"action_mask\"]  # e.g., [1, 0, 1, 1]\n</code></pre> <p>See Also: - Duration Guide - Understanding ticks and SMDP discounting - Interface Guide - Choosing index vs direct - Error Handling - Debugging failed options - Examples - Complete working examples</p>"},{"location":"durations/","title":"Durations and SMDP Discounting","text":"<p>Duration in SMDPfier v0.2.0+ is simple: each primitive action = 1 tick, and option duration equals the number of primitive actions executed (k_exec).</p>"},{"location":"durations/#time-semantics-v020","title":"\ud83c\udfaf Time Semantics (v0.2.0+)","text":"<p>The key principle: Each primitive action = 1 tick of time.</p> Concept Value Tick One primitive action execution Option Duration Number of primitive actions executed (k_exec) Complete Execution duration = <code>len(option.actions)</code> Partial Execution duration = number of actions before termination"},{"location":"durations/#simple-example","title":"Simple Example","text":"<pre><code>from smdpfier import SMDPfier, Option\nimport gymnasium as gym\n\nenv = gym.make(\"CartPole-v1\")\noptions = [\n    Option([0, 1, 0], \"three-step\"),      # 3 actions = 3 ticks\n    Option([1, 1, 0, 0], \"four-step\"),    # 4 actions = 4 ticks\n    Option([0, 1], \"two-step\"),           # 2 actions = 2 ticks\n]\n\nsmdp_env = SMDPfier(env, options_provider=options, action_interface=\"index\", max_options=3)\n\n# Execute first option (3 actions)\nobs, reward, term, trunc, info = smdp_env.step(0)\n\n# Check duration\nassert info[\"smdp\"][\"duration\"] == 3  # 3 actions executed = 3 ticks\nassert info[\"smdp\"][\"k_exec\"] == 3    # Same value\n</code></pre>"},{"location":"durations/#visual-example","title":"Visual Example","text":"<pre><code>Option: [0, 1, 0, 1, 1]  (5 actions)\n\nNormal Execution:\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a=0 \u2502 a=1 \u2502 a=0 \u2502 a=1 \u2502 a=1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\ntick:   1     2     3     4     5    \u2192 duration = 5\n\nEarly Termination (after 3 actions):\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510  X\n\u2502 a=0 \u2502 a=1 \u2502 a=0 \u2502 episode ends\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\ntick:   1     2     3                \u2192 duration = 3\n</code></pre>"},{"location":"durations/#smdp-discounting","title":"\ud83d\udd04 SMDP Discounting","text":"<p>With simple duration = k_exec, SMDP discounting becomes straightforward:</p>"},{"location":"durations/#basic-discounting","title":"Basic Discounting","text":"<pre><code>gamma = 0.99\n\n# Execute option\nobs, reward, term, trunc, info = env.step(action)\nduration = info[\"smdp\"][\"duration\"]\n\n# Apply SMDP discount\ndiscounted_reward = reward * (gamma ** duration)\n</code></pre>"},{"location":"durations/#multi-step-example","title":"Multi-Step Example","text":"<pre><code># Execute sequence of options\ngamma = 0.99\ntotal_time = 0\ncumulative_return = 0\n\nfor action in [0, 1, 2]:\n    obs, reward, term, trunc, info = env.step(action)\n    duration = info[\"smdp\"][\"duration\"]\n\n    # Apply time-cumulative discount\n    discount_factor = gamma ** total_time\n    cumulative_return += reward * discount_factor\n\n    total_time += duration\n    if term or trunc:\n        break\n\nprint(f\"Total time: {total_time} ticks\")\nprint(f\"Cumulative return: {cumulative_return}\")\n</code></pre>"},{"location":"durations/#comparison-mdp-vs-smdp","title":"Comparison: MDP vs SMDP","text":"<pre><code># MDP: Each primitive action discounts by \u03b3\nmdp_return = r\u2080 + \u03b3\u00b9\u00b7r\u2081 + \u03b3\u00b2\u00b7r\u2082 + \u03b3\u00b3\u00b7r\u2083 + \u03b3\u2074\u00b7r\u2084\n\n# SMDP: Each option discounts by \u03b3^{duration}\n# Options with lengths [3, 2, 4]:\nsmdp_return = R\u2080 + \u03b3\u00b3\u00b7R\u2081 + \u03b3\u2075\u00b7R\u2082\n#                   \u2191      \u2191\n#                   3    3+2\n</code></pre>"},{"location":"durations/#reward-aggregation","title":"\ud83d\udcca Reward Aggregation","text":"<p>By default, SMDPfier sums the per-step rewards to produce the macro reward:</p> <pre><code># Default behavior (v0.2.0+)\nmacro_reward = sum(primitive_rewards)\n\n# Example:\n# Option executes 3 steps with rewards [1.0, 1.0, 1.0]\n# macro_reward = 1.0 + 1.0 + 1.0 = 3.0\n</code></pre>"},{"location":"durations/#custom-aggregators","title":"Custom Aggregators","text":"<p>You can customize reward aggregation:</p> <pre><code>from smdpfier import SMDPfier\nfrom smdpfier.defaults import mean_rewards, discounted_sum\n\n# Average per-step rewards\nenv = SMDPfier(env, options_provider=options, reward_agg=mean_rewards)\n# 3 steps with rewards [1.0, 1.0, 1.0] \u2192 macro_reward = 1.0\n\n# Discount per-step rewards\nenv = SMDPfier(env, options_provider=options, reward_agg=discounted_sum(gamma=0.99))\n# 3 steps with rewards [1.0, 1.0, 1.0] \u2192 macro_reward = 1.0 + 0.99 + 0.98 = 2.97\n\n# Custom aggregator\ndef custom_agg(rewards):\n    return sum(r * (i + 1) for i, r in enumerate(rewards))  # Weighted sum\n\nenv = SMDPfier(env, options_provider=options, reward_agg=custom_agg)\n</code></pre>"},{"location":"durations/#early-termination","title":"\u26a0\ufe0f Early Termination","text":"<p>When the episode terminates before an option completes, duration reflects actual execution:</p> <pre><code>option = Option([0, 1, 0, 1, 1], \"five-step\")\n\n# Episode terminates after 3rd action\n# - k_exec = 3\n# - duration = 3 (not 5!)\n# - rewards = [r\u2081, r\u2082, r\u2083] (only 3 rewards)\n# - terminated_early = True\n\nobs, reward, term, trunc, info = env.step(option)\nif info[\"smdp\"][\"terminated_early\"]:\n    print(f\"Option interrupted after {info['smdp']['k_exec']} of {info['smdp']['option']['len']} actions\")\n    print(f\"Duration: {info['smdp']['duration']} ticks (not {info['smdp']['option']['len']})\")\n</code></pre>"},{"location":"durations/#why-this-matters-for-discounting","title":"Why This Matters for Discounting","text":"<pre><code># Option length: 5 actions\n# Terminated after 3 actions\n\n# \u2705 Correct: Use actual duration\nduration = info[\"smdp\"][\"duration\"]  # = 3\nnext_discount = gamma ** duration    # = \u03b3\u00b3\n\n# \u274c Wrong: Use planned duration\nplanned = info[\"smdp\"][\"option\"][\"len\"]  # = 5\nwrong_discount = gamma ** planned         # = \u03b3\u2075 (incorrect!)\n</code></pre>"},{"location":"durations/#full-example","title":"\ud83e\uddea Full Example","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\n\n# Setup\nenv = gym.make(\"CartPole-v1\")\noptions = [\n    Option([0, 0, 1], \"left-left-right\"),    # 3 ticks\n    Option([1, 1, 0, 0], \"right-right-left-left\"),  # 4 ticks\n]\n\nsmdp_env = SMDPfier(\n    env,\n    options_provider=options,\n    action_interface=\"index\",\n    max_options=2\n)\n\n# Episode\nobs, info = smdp_env.reset()\ngamma = 0.99\ntotal_time = 0\nreturns = []\n\nfor step in range(10):\n    action = smdp_env.action_space.sample()\n    obs, reward, term, trunc, info = smdp_env.step(action)\n\n    smdp = info[\"smdp\"]\n    duration = smdp[\"duration\"]\n\n    print(f\"Step {step}:\")\n    print(f\"  Option: {smdp['option']['name']}\")\n    print(f\"  Duration: {duration} ticks\")\n    print(f\"  Rewards: {smdp['rewards']}\")\n    print(f\"  Macro reward: {reward}\")\n    print(f\"  Discounted: {reward * (gamma ** total_time):.4f}\")\n\n    total_time += duration\n    returns.append(reward * (gamma ** total_time))\n\n    if term or trunc:\n        break\n\nprint(f\"\\nTotal time: {total_time} ticks\")\nprint(f\"Total return: {sum(returns):.4f}\")\n</code></pre>"},{"location":"durations/#key-takeaways","title":"\ud83d\udcdd Key Takeaways","text":"<ol> <li>Each primitive action = 1 tick: Time is simple and natural</li> <li>Duration = k_exec: No separate duration function needed</li> <li>Early termination: Duration reflects actual execution, not planned</li> <li>SMDP discounting: Use <code>\u03b3^{duration}</code> for each option</li> <li>Macro reward: Sum of per-step rewards by default (customizable)</li> </ol>"},{"location":"durations/#migrating-from-01x","title":"\ud83d\udd04 Migrating from 0.1.x","text":"<p>In v0.1.x, you had to specify a <code>duration_fn</code>. In v0.2.0+, this is automatic:</p> <pre><code># 0.1.x - Old way\nfrom smdpfier.defaults import ConstantActionDuration\n\nenv = SMDPfier(\n    env,\n    options_provider=options,\n    duration_fn=ConstantActionDuration(1),  # Each action = 1 tick\n    # ...\n)\n\n# 0.2.0+ - New way (automatic!)\nenv = SMDPfier(\n    env,\n    options_provider=options,\n    # duration_fn removed - each action automatically = 1 tick\n    # ...\n)\n</code></pre> <p>See Migration Guide for complete upgrade instructions.</p> <p>Next: FAQ | Previous: API Reference - When different actions have different inherent durations</p>"},{"location":"durations/#duration-type-comparison","title":"Duration Type Comparison","text":"Scenario Scalar Duration List Duration Option: <code>[0,1,0]</code> <code>10</code> \u2192 10 ticks total <code>[3,4,3]</code> \u2192 10 ticks total Early Termination Apply partial duration policy Sum executed portion Complexity Simple More detailed Use Case Macro-actions Action-specific costs"},{"location":"durations/#smdp-discounting_1","title":"SMDP Discounting","text":"<p>The power of SMDPs lies in proper temporal discounting using elapsed time rather than step counts.</p>"},{"location":"durations/#standard-mdp-vs-smdp","title":"Standard MDP vs SMDP","text":"<p>Standard MDP Discounting: <pre><code># Each step advances time by exactly 1 unit\nreturn = r\u2081 + \u03b3\u00b9\u00b7r\u2082 + \u03b3\u00b2\u00b7r\u2083 + \u03b3\u00b3\u00b7r\u2084 + ...\n#           \u2191    \u2191    \u2191    \u2191\n#          t=1  t=2  t=3  t=4\n</code></pre></p> <p>SMDP Discounting: <pre><code># Each option advances time by its duration\n# Options with durations [5, 3, 7, 2] ticks:\nreturn = r\u2081 + \u03b3\u2075\u00b7r\u2082 + \u03b3\u2078\u00b7r\u2083 + \u03b3\u00b9\u2075\u00b7r\u2084 + \u03b3\u00b9\u2077\u00b7r\u2085\n#           \u2191     \u2191     \u2191      \u2191      \u2191\n#          t=0   t=5   t=8   t=15   t=17\n</code></pre></p>"},{"location":"durations/#practical-smdp-discounting-implementation","title":"Practical SMDP Discounting Implementation","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import ConstantOptionDuration\n\n# Setup\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=[\n        Option([0, 0], \"left-left\"),     # 2 steps, 10 ticks\n        Option([1, 1, 1], \"right-x3\"),   # 3 steps, 10 ticks  \n        Option([0, 1], \"left-right\"),    # 2 steps, 10 ticks\n    ],\n    duration_fn=ConstantOptionDuration(10)\n)\n\n# Episode with SMDP discounting\ngamma = 0.99\ndiscounted_return = 0\nelapsed_time = 0\n\nobs, info = env.reset()\nfor step in range(3):\n    action = step % 3  # Cycle through options\n    obs, reward, term, trunc, info = env.step(action)\n\n    # Get duration from SMDP info\n    duration = info[\"smdp\"][\"duration_exec\"]\n\n    # Apply SMDP discounting\n    discount_factor = gamma ** elapsed_time\n    discounted_return += discount_factor * reward\n\n    # Update elapsed time for next option\n    elapsed_time += duration\n\n    print(f\"Option {action}: reward={reward}, duration={duration}, \"\n          f\"discount=\u03b3^{elapsed_time-duration}={discount_factor:.4f}\")\n\n    if term or trunc:\n        break\n\nprint(f\"Total SMDP discounted return: {discounted_return:.4f}\")\n</code></pre> <p>Sample Output: <pre><code>Option 0: reward=2.0, duration=10, discount=\u03b3^0=1.0000\nOption 1: reward=3.0, duration=10, discount=\u03b3^10=0.9044  \nOption 2: reward=1.0, duration=10, discount=\u03b3^20=0.8179\nTotal SMDP discounted return: 4.6223\n</code></pre></p>"},{"location":"durations/#partial-duration-policies","title":"Partial Duration Policies","text":"<p>When an episode terminates early (before an option completes), SMDPfier applies a partial duration policy to determine the executed duration.</p>"},{"location":"durations/#policy-comparison","title":"Policy Comparison","text":"<p>Consider an option with 3 actions and scalar duration 10, terminating after 2 actions:</p> Policy Formula Result Use Case <code>\"proportional\"</code> <code>(k_exec / option_len) * planned_duration</code> <code>(2/3) * 10 = 6</code> Default - proportional time <code>\"full\"</code> <code>planned_duration</code> <code>10</code> Option \"completes\" conceptually <code>\"zero\"</code> <code>0</code> <code>0</code> No time passes on failure"},{"location":"durations/#example-partial-duration-calculation","title":"Example: Partial Duration Calculation","text":"<pre><code>from smdpfier.defaults import ConstantOptionDuration\n\n# Option with 4 actions, 12 ticks planned\noption = Option([0, 1, 0, 1], \"four-action-option\")\nduration_fn = ConstantOptionDuration(12)\n\n# Episode terminates after 3 actions (k_exec = 3)\n\n# Proportional policy (default):\nduration_exec = (3 / 4) * 12 = 9 ticks\n\n# Full policy:  \nduration_exec = 12 ticks\n\n# Zero policy:\nduration_exec = 0 ticks\n</code></pre>"},{"location":"durations/#policy-selection-guide","title":"Policy Selection Guide","text":"Choose When <code>\"proportional\"</code> Time should scale with execution (most realistic) <code>\"full\"</code> Options have setup costs regardless of completion <code>\"zero\"</code> Failed options should not consume time"},{"location":"durations/#advanced-duration-functions","title":"Advanced Duration Functions","text":""},{"location":"durations/#custom-duration-functions","title":"Custom Duration Functions","text":"<pre><code>def custom_duration_fn(option, obs, info):\n    \"\"\"Duration based on option length and environment state.\"\"\"\n    base_duration = len(option.actions) * 2\n\n    # Adjust based on environment state  \n    if obs[0] &gt; 0:  # Cart position in CartPole\n        return base_duration + 5  # Takes longer when cart is right\n    else:\n        return base_duration\n\n# Usage\nenv = SMDPfier(env, options_provider=options, duration_fn=custom_duration_fn)\n</code></pre>"},{"location":"durations/#state-dependent-durations","title":"State-Dependent Durations","text":"<pre><code>from smdpfier.defaults import MapActionDuration\n\n# Different actions have different costs\naction_duration_map = {\n    0: 2,  # Left action: 2 ticks\n    1: 5,  # Right action: 5 ticks (more expensive)\n}\n\nduration_fn = MapActionDuration(action_duration_map, default_duration=3)\n\n# Option [0, 1, 0] \u2192 durations [2, 5, 2] \u2192 total 9 ticks\n</code></pre>"},{"location":"durations/#summary","title":"Summary","text":"Concept Key Point Steps vs Ticks Steps = execution, Ticks = time metadata Duration Types Scalar (per-option) vs List (per-action) SMDP Discounting Use \u03b3^{duration_exec}, not \u03b3^{steps} Partial Policies Handle early termination gracefully Custom Functions Tailor durations to your domain <p>Remember: Duration is metadata for discounting - it never affects how many environment steps are executed!</p> <p>Next: Index vs Direct Interfaces | See Also: API Reference</p>"},{"location":"errors/","title":"Error Handling","text":"<p>SMDPfier provides comprehensive error handling with detailed context information to help debug option execution issues and build robust SMDP applications.</p>"},{"location":"errors/#error-types","title":"Error Types","text":"<p>SMDPfier defines specialized exceptions that provide rich context about option failures, making debugging much easier than generic exceptions.</p>"},{"location":"errors/#smdpoptionvalidationerror","title":"SMDPOptionValidationError","text":"<p>Raised during precheck validation when an option is determined to be invalid before execution.</p> <pre><code>from smdpfier.errors import SMDPOptionValidationError\n\ntry:\n    obs, reward, term, trunc, info = env.step(invalid_option_index)\nexcept SMDPOptionValidationError as e:\n    print(f\"Validation failed for option '{e.option_name}' (ID: {e.option_id})\")\n    print(f\"Validation type: {e.validation_type}\")\n    print(f\"Failed at step {e.failing_step_index} with action {e.action_repr}\")\n    print(f\"Environment state: {e.short_obs_summary}\")\n    if e.base_error:\n        print(f\"Underlying error: {e.base_error}\")\n</code></pre>"},{"location":"errors/#smdpoptionexecutionerror","title":"SMDPOptionExecutionError","text":"<p>Raised during option execution when a primitive action fails at runtime.</p> <pre><code>from smdpfier.errors import SMDPOptionExecutionError\n\ntry:\n    obs, reward, term, trunc, info = env.step(problematic_option_index)\nexcept SMDPOptionExecutionError as e:\n    print(f\"Execution failed for option '{e.option_name}' (ID: {e.option_id})\")\n    print(f\"Failed at step {e.failing_step_index} with action {e.action_repr}\")\n    print(f\"Environment state: {e.short_obs_summary}\")\n    if e.base_error:\n        print(f\"Underlying error: {e.base_error}\")\n</code></pre>"},{"location":"errors/#error-context-fields","title":"Error Context Fields","text":"<p>Both error types provide comprehensive context information:</p> Field Type Description <code>option_name</code> <code>str</code> Human-readable name of the failing option <code>option_id</code> <code>str</code> Unique identifier for the option (hash-based) <code>failing_step_index</code> <code>int</code> Which action in the sequence failed (0-indexed) <code>action_repr</code> <code>str</code> String representation of the failing action <code>short_obs_summary</code> <code>str</code> Abbreviated environment state description <code>base_error</code> <code>Exception \\| None</code> Original exception that caused the failure <code>validation_type</code> <code>str</code> Type of validation that failed (ValidationError only)"},{"location":"errors/#error-context-example","title":"Error Context Example","text":"<pre><code># When this option fails:\nproblematic_option = Option([0, 1, 99], \"problematic-sequence\")\n\n# You get detailed context:\n# SMDPOptionExecutionError: Option execution failed\n#   option_name: \"problematic-sequence\"\n#   option_id: \"abc123def456...\"\n#   failing_step_index: 2\n#   action_repr: \"99\"\n#   short_obs_summary: \"obs=[0.1, -0.3, 0.05, ...] (CartPole-v1)\"\n#   base_error: ValueError(\"Invalid action 99 for Discrete(2) action space\")\n</code></pre>"},{"location":"errors/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"errors/#invalid-action-for-action-space","title":"Invalid Action for Action Space","text":"<p>Most common error - action not in environment's action space.</p> <pre><code># CartPole has Discrete(2) action space (actions 0, 1)\ninvalid_option = Option([0, 1, 2], \"invalid-action\")  # Action 2 is invalid\n\ntry:\n    obs, reward, term, trunc, info = env.step(invalid_option)\nexcept SMDPOptionExecutionError as e:\n    print(f\"Invalid action {e.action_repr} at step {e.failing_step_index}\")\n    # Output: \"Invalid action 2 at step 2\"\n</code></pre> <p>Solution strategies: <pre><code># Strategy 1: Validate options at creation\ndef create_safe_option(actions, name, action_space):\n    \"\"\"Create option with action space validation.\"\"\"\n    if isinstance(action_space, gym.spaces.Discrete):\n        valid_actions = list(range(action_space.n))\n        invalid_actions = [a for a in actions if a not in valid_actions]\n        if invalid_actions:\n            raise ValueError(f\"Invalid actions {invalid_actions} for {action_space}\")\n\n    return Option(actions, name)\n\n# Strategy 2: Use masking to prevent invalid options\ndef safe_availability(obs):\n    \"\"\"Only allow options with valid actions.\"\"\"\n    return [0, 1, 2]  # Indices of options with valid actions only\n</code></pre></p>"},{"location":"errors/#continuous-action-shape-mismatch","title":"Continuous Action Shape Mismatch","text":"<p>Continuous environments require actions with correct shape.</p> <pre><code># Pendulum expects actions with shape (1,)\nwrong_shape_option = Option([[1.0, 2.0]], \"wrong-shape\")  # Shape (2,) - wrong!\ncorrect_option = Option([[1.5]], \"correct-shape\")         # Shape (1,) - correct\n\ntry:\n    obs, reward, term, trunc, info = env.step(wrong_shape_option)\nexcept SMDPOptionExecutionError as e:\n    print(f\"Shape error: {e.base_error}\")\n    # Output: \"Shape error: ValueError('Expected action shape (1,), got (2,)')\"\n</code></pre>"},{"location":"errors/#environment-state-issues","title":"Environment State Issues","text":"<p>Some environments have state-dependent action validity.</p> <pre><code># Taxi environment - pickup only valid at passenger locations\ndef taxi_example():\n    env = SMDPfier(gym.make(\"Taxi-v3\"), ...)\n\n    # This might fail if taxi is not at passenger location\n    pickup_option = Option([4], \"pickup\")  # Action 4 = pickup\n\n    try:\n        obs, reward, term, trunc, info = env.step(pickup_option)\n    except SMDPOptionExecutionError as e:\n        if \"pickup\" in str(e.base_error).lower():\n            print(\"Pickup failed - taxi not at passenger location\")\n            # Try movement instead\n            move_option = Option([0], \"move-south\")\n            obs, reward, term, trunc, info = env.step(move_option)\n</code></pre>"},{"location":"errors/#early-termination-during-option","title":"Early Termination During Option","text":"<p>Episode termination during option execution is handled gracefully (not an error), but understanding the behavior is important.</p> <pre><code># Long option that might cause episode termination\nlong_option = Option([0] * 10, \"ten-left-actions\")\n\nobs, reward, term, trunc, info = env.step(long_option)\n\n# Check if option completed\nsmdp_info = info[\"smdp\"]\nif smdp_info[\"terminated_early\"]:\n    print(f\"Episode ended after {smdp_info['k_exec']} of {smdp_info['option']['len']} actions\")\n    print(f\"Partial duration: {smdp_info['duration_exec']} ticks\")\n</code></pre>"},{"location":"errors/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"errors/#basic-try-catch-pattern","title":"Basic Try-Catch Pattern","text":"<pre><code>def robust_step(env, action):\n    \"\"\"Robust step with error handling.\"\"\"\n    try:\n        return env.step(action)\n    except SMDPOptionValidationError as e:\n        print(f\"Precheck failed: {e.option_name} at step {e.failing_step_index}\")\n        # Return safe fallback or re-raise\n        raise\n    except SMDPOptionExecutionError as e:\n        print(f\"Execution failed: {e.option_name} with action {e.action_repr}\")\n        # Return safe fallback or re-raise  \n        raise\n</code></pre>"},{"location":"errors/#fallback-strategy-pattern","title":"Fallback Strategy Pattern","text":"<pre><code>def execute_with_fallback(env, primary_option, fallback_options):\n    \"\"\"Try primary option, fall back to alternatives on failure.\"\"\"\n\n    # Try primary option\n    try:\n        return env.step(primary_option)\n    except (SMDPOptionValidationError, SMDPOptionExecutionError) as e:\n        print(f\"Primary option failed: {e}\")\n\n        # Try fallback options\n        for i, fallback in enumerate(fallback_options):\n            try:\n                print(f\"Trying fallback {i+1}: {fallback.name}\")\n                return env.step(fallback)\n            except (SMDPOptionValidationError, SMDPOptionExecutionError):\n                continue\n\n        # All options failed\n        raise RuntimeError(\"All options failed, no valid actions available\")\n\n# Usage\nprimary = Option([0, 1, 0, 1], \"complex-sequence\")\nfallbacks = [\n    Option([0, 1], \"simple-sequence\"),\n    Option([0], \"minimal-action\"),\n]\n\nobs, reward, term, trunc, info = execute_with_fallback(env, primary, fallbacks)\n</code></pre>"},{"location":"errors/#logging-and-monitoring-pattern","title":"Logging and Monitoring Pattern","text":"<pre><code>import logging\n\nlogger = logging.getLogger(\"smdp_errors\")\n\ndef monitored_step(env, action):\n    \"\"\"Step with comprehensive error logging.\"\"\"\n    try:\n        result = env.step(action)\n\n        # Log successful execution details\n        smdp_info = result[4][\"smdp\"]  # info[\"smdp\"]\n        logger.info(f\"Option '{smdp_info['option']['name']}' executed successfully\")\n        logger.debug(f\"Steps: {smdp_info['k_exec']}, Duration: {smdp_info['duration_exec']}\")\n\n        return result\n\n    except SMDPOptionValidationError as e:\n        logger.error(f\"Validation error: {e.option_name} failed at step {e.failing_step_index}\")\n        logger.error(f\"Action: {e.action_repr}, State: {e.short_obs_summary}\")\n        logger.debug(f\"Full error: {e}\")\n        raise\n\n    except SMDPOptionExecutionError as e:\n        logger.error(f\"Execution error: {e.option_name} failed at step {e.failing_step_index}\")\n        logger.error(f\"Action: {e.action_repr}, Base error: {e.base_error}\")\n        logger.debug(f\"Full error: {e}\")\n        raise\n</code></pre>"},{"location":"errors/#error-recovery-for-rl-training","title":"Error Recovery for RL Training","text":"<pre><code>class ErrorResilientAgent:\n    def __init__(self, env):\n        self.env = env\n        self.error_counts = {}\n        self.max_error_threshold = 5\n\n    def step_with_recovery(self, action):\n        \"\"\"RL training step with error recovery.\"\"\"\n        try:\n            return self.env.step(action)\n\n        except (SMDPOptionValidationError, SMDPOptionExecutionError) as e:\n            # Track error frequency\n            error_key = (e.option_name, e.failing_step_index)\n            self.error_counts[error_key] = self.error_counts.get(error_key, 0) + 1\n\n            # If this error happens too often, it's a systematic issue\n            if self.error_counts[error_key] &gt; self.max_error_threshold:\n                print(f\"Systematic error detected: {error_key}\")\n                # Could trigger option blacklisting, environment reset, etc.\n\n            # For training, reset environment and continue\n            print(f\"Error during training: {e.option_name}, resetting episode\")\n            obs, info = self.env.reset()\n            return obs, 0.0, True, False, info  # Return terminal step\n\n    def get_error_statistics(self):\n        \"\"\"Get error frequency statistics.\"\"\"\n        return dict(self.error_counts)\n</code></pre>"},{"location":"errors/#debugging-techniques","title":"Debugging Techniques","text":""},{"location":"errors/#option-validation","title":"Option Validation","text":"<pre><code>def validate_option_thoroughly(env, option):\n    \"\"\"Comprehensive option validation.\"\"\"\n    print(f\"Validating option: {option.name}\")\n    print(f\"Actions: {option.actions}\")\n    print(f\"Action count: {len(option.actions)}\")\n\n    # Check action space compatibility\n    action_space = env.unwrapped.action_space\n    print(f\"Environment action space: {action_space}\")\n\n    for i, action in enumerate(option.actions):\n        if isinstance(action_space, gym.spaces.Discrete):\n            if not (0 &lt;= action &lt; action_space.n):\n                print(f\"  \u274c Action {i}: {action} invalid for {action_space}\")\n            else:\n                print(f\"  \u2705 Action {i}: {action} valid\")\n        elif isinstance(action_space, gym.spaces.Box):\n            action = np.array(action)\n            if action.shape != action_space.shape:\n                print(f\"  \u274c Action {i}: shape {action.shape} != {action_space.shape}\")\n            elif not action_space.contains(action):\n                print(f\"  \u274c Action {i}: {action} outside bounds {action_space}\")\n            else:\n                print(f\"  \u2705 Action {i}: {action} valid\")\n</code></pre>"},{"location":"errors/#error-pattern-analysis","title":"Error Pattern Analysis","text":"<pre><code>def analyze_error_patterns(error_log):\n    \"\"\"Analyze common error patterns from logs.\"\"\"\n    error_types = {}\n    failing_actions = {}\n    failing_options = {}\n\n    for error in error_log:\n        # Group by error type\n        error_type = type(error).__name__\n        error_types[error_type] = error_types.get(error_type, 0) + 1\n\n        # Group by failing action\n        action = error.action_repr\n        failing_actions[action] = failing_actions.get(action, 0) + 1\n\n        # Group by option name\n        option = error.option_name\n        failing_options[option] = failing_options.get(option, 0) + 1\n\n    print(\"Error Analysis:\")\n    print(f\"Error types: {error_types}\")\n    print(f\"Most failing actions: {sorted(failing_actions.items(), key=lambda x: x[1], reverse=True)[:5]}\")\n    print(f\"Most failing options: {sorted(failing_options.items(), key=lambda x: x[1], reverse=True)[:5]}\")\n</code></pre>"},{"location":"errors/#interactive-debugging","title":"Interactive Debugging","text":"<pre><code>def debug_option_interactively(env, option):\n    \"\"\"Step through option execution interactively.\"\"\"\n    print(f\"Debug mode for option: {option.name}\")\n    print(f\"Actions to execute: {option.actions}\")\n\n    obs, info = env.reset()\n    print(f\"Initial state: {obs}\")\n\n    for i, action in enumerate(option.actions):\n        print(f\"\\nStep {i}: About to execute action {action}\")\n        input(\"Press Enter to continue...\")\n\n        try:\n            obs, reward, term, trunc, info = env.step(action)\n            print(f\"Result: obs={obs[:3]}..., reward={reward}, term={term}, trunc={trunc}\")\n\n            if term or trunc:\n                print(\"Episode terminated!\")\n                break\n\n        except Exception as e:\n            print(f\"Error at step {i}: {e}\")\n            break\n</code></pre>"},{"location":"errors/#error-prevention","title":"Error Prevention","text":""},{"location":"errors/#option-design-guidelines","title":"Option Design Guidelines","text":"<pre><code># \u2705 Good: Simple, robust options\ngood_options = [\n    Option([0], \"single-left\"),           # Minimal failure risk\n    Option([1], \"single-right\"),          # Minimal failure risk  \n    Option([0, 1], \"balanced\"),           # Self-correcting\n]\n\n# \u274c Avoid: Complex, risky options\nrisky_options = [\n    Option([0] * 20, \"extreme-long\"),     # High termination risk\n    Option([999], \"invalid-action\"),      # Invalid action\n    Option([0, 1, 0, 1, 0, 1], \"too-long\"), # Long sequence risk\n]\n</code></pre>"},{"location":"errors/#environment-specific-safety","title":"Environment-Specific Safety","text":"<pre><code>def create_safe_cartpole_options():\n    \"\"\"Create CartPole options with built-in safety.\"\"\"\n    # CartPole actions: 0 (left), 1 (right)\n    safe_options = [\n        Option([0], \"left\"),\n        Option([1], \"right\"),\n        Option([0, 1], \"left-right\"),     # Balanced\n        Option([1, 0], \"right-left\"),     # Balanced\n        # Avoid long sequences that might cause termination\n    ]\n    return safe_options\n\ndef create_safe_pendulum_options():\n    \"\"\"Create Pendulum options with proper action ranges.\"\"\"\n    # Pendulum action space: Box([-2.0], [2.0])\n    safe_options = [\n        Option([[-2.0]], \"max-left\"),\n        Option([[2.0]], \"max-right\"),\n        Option([[0.0]], \"no-torque\"),\n        Option([[-1.0], [1.0]], \"swing\"),\n        Option([[0.5], [0.5]], \"gentle-right\"),\n    ]\n    return safe_options\n</code></pre>"},{"location":"errors/#summary","title":"Summary","text":"Error Type When It Occurs How to Handle <code>SMDPOptionValidationError</code> Precheck failure Disable precheck or fix option <code>SMDPOptionExecutionError</code> Runtime action failure Use fallbacks or fix option Early termination Episode ends during option Normal behavior, check <code>terminated_early</code> <p>Best Practices: 1. Design robust options with minimal failure risk 2. Use action masking to prevent invalid options 3. Implement fallback strategies for critical applications 4. Log errors comprehensively for debugging 5. Test options thoroughly in development</p> <p>Key Takeaway: SMDPfier's detailed error context makes debugging much easier than generic exceptions. Use this information to build robust, error-resilient SMDP applications.</p> <p>Next: FAQ | See Also: Masking and Precheck</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Common questions and answers about SMDPfier concepts, usage, and troubleshooting.</p>"},{"location":"faq/#core-concepts","title":"Core Concepts","text":""},{"location":"faq/#what-is-smdpfier","title":"What is SMDPfier?","text":"<p>SMDPfier is a Gymnasium wrapper that transforms any environment into a Semi-Markov Decision Process (SMDP) by enabling: - Options: Sequences of primitive actions executed atomically - Simple Time Semantics: Each primitive action = 1 tick (v0.2.0+) - SMDP Discounting: Using \u03b3^{k} where k = number of actions executed</p> <p>Key Insight (v0.2.0+): Each primitive action = 1 tick. Duration = k_exec. Simple and natural.</p>"},{"location":"faq/#how-is-this-different-from-other-hierarchical-rl-libraries","title":"How is this different from other hierarchical RL libraries?","text":"Aspect SMDPfier Other Libraries Focus Option-based SMDP behavior General hierarchical RL Complexity Single wrapper class Full frameworks Environment Support Any Gymnasium env unchanged Often require specific environments Temporal Modeling Each action = 1 tick Usually step-based Integration Drop-in wrapper Framework-specific"},{"location":"faq/#when-should-i-use-smdpfier","title":"When should I use SMDPfier?","text":"<p>\u2705 Use SMDPfier when you want to: - Apply SMDP discounting with \u03b3^{duration} where duration = actions executed - Test hierarchical policies with temporal abstractions - Add option-level control to existing environments - Research temporal abstractions with simple time semantics</p> <p>\u274c Don't use SMDPfier when: - You need complex option discovery algorithms - You want full hierarchical RL frameworks (use HRL libraries) - You don't care about temporal discounting (standard MDP is fine)</p>"},{"location":"faq/#time-semantics-v020","title":"Time Semantics (v0.2.0+)","text":""},{"location":"faq/#how-does-time-work-in-smdpfier","title":"How does time work in SMDPfier?","text":"<p>Simple rule: Each primitive action = 1 tick.</p> <pre><code>option = Option([0, 1, 0], \"three-actions\")  # 3 actions\n\n# Executes 3 primitive actions \u2192 duration = 3 ticks\n# If terminated early after 2 actions \u2192 duration = 2 ticks\n</code></pre>"},{"location":"faq/#why-did-duration-modeling-change-in-v020","title":"Why did duration modeling change in v0.2.0?","text":"<p>Simplicity and clarity. The old system separated \"steps\" from \"ticks\" which was confusing. Now: - Each action = 1 tick (natural and intuitive) - Duration = k_exec (number of actions executed) - No complex duration functions needed</p> <p>See Migration Guide for upgrading from 0.1.x.</p>"},{"location":"faq/#how-do-i-control-option-duration","title":"How do I control option duration?","text":"<p>Use option length:</p> <pre><code># Want 2 ticks? Use 2 actions:\nshort_option = Option([0, 1], \"short\")           # 2 ticks\n\n# Want 5 ticks? Use 5 actions:\nlong_option = Option([0, 1, 0, 1, 0], \"long\")    # 5 ticks\n\n# Want 1 tick? Use 1 action:\ninstant_option = Option([0], \"instant\")          # 1 tick\n</code></pre>"},{"location":"faq/#smdp-discounting","title":"SMDP Discounting","text":""},{"location":"faq/#how-do-i-apply-smdp-discounting","title":"How do I apply SMDP discounting?","text":"<p>Use <code>duration</code> from the info payload:</p> <pre><code>obs, reward, term, trunc, info = env.step(action)\n\n# Get duration (equals k_exec)\nduration = info[\"smdp\"][\"duration\"]\n\n# Apply SMDP discounting\ngamma = 0.99\ndiscounted_reward = reward * (gamma ** duration)\n\n# Track cumulative time for multi-step discounting\ntotal_time += duration\nnext_discount = gamma ** total_time\n</code></pre>"},{"location":"faq/#what-happens-with-early-termination","title":"What happens with early termination?","text":"<p>When the episode terminates before an option completes, <code>duration</code> reflects actual execution:</p> <pre><code># Option has 5 actions, but episode terminates after 2 actions\n\ninfo[\"smdp\"] = {\n    \"k_exec\": 2,              # 2 actions executed\n    \"duration\": 2,            # 2 ticks (= k_exec)\n    \"terminated_early\": True  # Flag indicating early termination\n}\n</code></pre> <p>Why this matters: - Use actual duration for discounting, not planned length - Prevents incorrect temporal credit assignment - Handles partial execution correctly</p>"},{"location":"faq/#action-interfaces","title":"Action Interfaces","text":""},{"location":"faq/#index-vs-direct-which-should-i-use","title":"Index vs Direct: Which should I use?","text":"Use Case Recommended Interface Why RL Training Index Discrete action space for algorithms Scripting/Testing Direct Intuitive option objects Action Masking Index Built-in mask support Debugging Direct Clear option identification Continuous Actions Direct Natural continuous support <p>Common Pattern: Start with direct for prototyping, switch to index for RL training.</p>"},{"location":"faq/#how-does-action-masking-work-in-index-interface","title":"How does action masking work in index interface?","text":"<pre><code>def availability_fn(obs):\n    \"\"\"Return available option indices.\"\"\"\n    if obs[0] &gt; 0.5:  # Cart far right\n        return [0, 2]  # Only left-based options\n    else:\n        return [0, 1, 2]  # All options\n\nenv = SMDPfier(..., availability_fn=availability_fn)\n\nobs, info = env.reset()\nmask = info[\"smdp\"][\"action_mask\"]  # e.g., [1, 0, 1] = options 0,2 available\n</code></pre>"},{"location":"faq/#what-happens-with-dynamic-options-overflow","title":"What happens with dynamic options overflow?","text":"<p>When dynamic options exceed <code>max_options</code>:</p> <pre><code>env = SMDPfier(..., max_options=3)\n\n# If generator returns 5 options:\n# - First 3 options are used\n# - Last 2 options are dropped  \n# - info[\"smdp\"][\"num_dropped\"] = 2\n</code></pre>"},{"location":"faq/#environment-compatibility","title":"Environment Compatibility","text":""},{"location":"faq/#can-i-use-continuous-actions","title":"Can I use continuous actions?","text":"<p>Yes! SMDPfier fully supports continuous action spaces:</p> <pre><code># Continuous options\ncontinuous_options = [\n    Option([[-1.0], [0.0], [1.0]], \"left-center-right\"),  # 3 ticks\n    Option([[0.5, 0.2]], \"multi-dim-action\"),             # 1 tick\n]\n\nenv = SMDPfier(\n    gym.make(\"Pendulum-v1\"),\n    options_provider=continuous_options,\n    action_interface=\"direct\"  # Recommended for continuous\n)\n</code></pre>"},{"location":"faq/#what-environments-work-with-smdpfier","title":"What environments work with SMDPfier?","text":"<p>Any Gymnasium environment! SMDPfier is a generic wrapper.</p> <p>\u2705 Confirmed Compatible: - CartPole, Pendulum, MountainCar - Atari games - MuJoCo environments - Custom environments - Multi-agent environments (with appropriate setup)</p>"},{"location":"faq/#what-happens-if-my-environment-terminates-during-an-option","title":"What happens if my environment terminates during an option?","text":"<p>SMDPfier handles this gracefully:</p> <ol> <li>Execution stops immediately when <code>env.step()</code> returns <code>terminated=True</code> or <code>truncated=True</code></li> <li>Duration reflects actual execution (duration = k_exec)</li> <li>Info payload contains early termination flag</li> </ol> <pre><code># Option with 5 actions, but episode terminates after 2 actions\ninfo[\"smdp\"] = {\n    \"k_exec\": 2,                    # Only 2 actions executed\n    \"duration\": 2,                  # 2 ticks (= k_exec)\n    \"terminated_early\": True,       # Flag early termination\n    # ...\n}\n</code></pre>"},{"location":"faq/#common-issues","title":"Common Issues","text":""},{"location":"faq/#my-rl-algorithm-isnt-learning-whats-wrong","title":"My RL algorithm isn't learning - what's wrong?","text":"<p>Common causes:</p> <ol> <li> <p>Wrong discounting: Use <code>duration</code>, not step count <pre><code># Wrong\ndiscount = gamma ** step_count\n\n# Right  \ndiscount = gamma ** info[\"smdp\"][\"duration\"]\n</code></pre></p> </li> <li> <p>Action space mismatch: Ensure max_options is correct <pre><code># Correct for static options\nmax_options = len(static_options)\n\n# Might be needed for dynamic options\nmax_options = 10  # Set appropriately\n</code></pre></p> </li> <li> <p>Reward aggregation: Check if default sum is appropriate <pre><code># Try different aggregation\nreward_agg = mean_rewards          # Average instead of sum\nreward_agg = discounted_sum(0.99)  # Internal discounting\n</code></pre></p> </li> </ol>"},{"location":"faq/#im-getting-smdpoptionvalidationerror-what-does-it-mean","title":"I'm getting SMDPOptionValidationError - what does it mean?","text":"<p>This means an option failed precheck validation:</p> <pre><code>try:\n    env.step(action)\nexcept SMDPOptionValidationError as e:\n    print(f\"Option '{e.option_name}' failed at step {e.failing_step_index}\")\n    print(f\"Action {e.action_repr} is invalid in current state\")\n    print(f\"State summary: {e.short_obs_summary}\")\n</code></pre> <p>Solutions: - Check if actions are valid for current environment state - Verify action space compatibility - Use availability_fn to mask invalid options - Turn off precheck: <code>precheck=False</code></p>"},{"location":"faq/#my-options-arent-being-executed-correctly","title":"My options aren't being executed correctly","text":"<p>Debug steps:</p> <ol> <li> <p>Check option construction: <pre><code>option = Option([0, 1, 0], \"test\")\nprint(f\"Actions: {option.actions}\")\nprint(f\"Length: {len(option.actions)}\")\n</code></pre></p> </li> <li> <p>Verify action validity: <pre><code># Test each action individually in base environment\nfor action in option.actions:\n    obs, reward, term, trunc, info = base_env.step(action)\n    if term or trunc:\n        print(f\"Action {action} terminates episode!\")\n</code></pre></p> </li> <li> <p>Check execution details: <pre><code>obs, reward, term, trunc, info = smdp_env.step(option)\nsmdp = info[\"smdp\"]\nprint(f\"Planned steps: {smdp['option']['len']}\")\nprint(f\"Executed steps: {smdp['k_exec']}\")\nprint(f\"Rewards: {smdp['rewards']}\")\n</code></pre></p> </li> </ol>"},{"location":"faq/#performance-is-slow-how-can-i-optimize","title":"Performance is slow - how can I optimize?","text":"<p>Performance tips:</p> <ol> <li> <p>Cache options when possible: <pre><code># Pre-compute static options\nstatic_options = [Option([i, j], f\"option_{i}_{j}\") \n                 for i in range(2) for j in range(2)]\n</code></pre></p> </li> <li> <p>Use simple reward aggregators: <pre><code># Simple aggregators are faster\nfrom smdpfier.defaults import sum_rewards, mean_rewards\nreward_agg = sum_rewards  # Fast\n</code></pre></p> </li> <li> <p>Use appropriate max_options: <pre><code># Don't over-allocate\nmax_options = 5   # If you typically have 3-5 options\n# vs  \nmax_options = 100 # Wastes memory and computation\n</code></pre></p> </li> </ol>"},{"location":"faq/#advanced-usage","title":"Advanced Usage","text":""},{"location":"faq/#can-i-modify-options-during-execution","title":"Can I modify options during execution?","text":"<p>No. Options are executed atomically. However, you can:</p> <ol> <li>Use dynamic options that change between executions</li> <li>Create context-aware generators that consider current state</li> <li>Implement early termination via environment design</li> </ol>"},{"location":"faq/#how-do-i-debug-option-sequences","title":"How do I debug option sequences?","text":"<p>Detailed info inspection:</p> <pre><code>obs, reward, term, trunc, info = env.step(action)\nsmdp = info[\"smdp\"]\n\nprint(\"=== Option Execution Details ===\")\nprint(f\"Option: {smdp['option']['name']} (ID: {smdp['option']['id']})\")\nprint(f\"Actions: {smdp['option']['len']} total\")\nprint(f\"Executed: {smdp['k_exec']} steps\")\nprint(f\"Duration: {smdp['duration']} ticks (= k_exec)\")\nprint(f\"Per-step rewards: {smdp['rewards']}\")\nprint(f\"Macro reward: {reward}\")\nprint(f\"Early termination: {smdp['terminated_early']}\")\n\nif smdp.get('action_mask'):\n    print(f\"Available options next: {smdp['action_mask']}\")\n</code></pre>"},{"location":"faq/#can-i-nest-smdpfiers","title":"Can I nest SMDPfiers?","text":"<p>Technically possible but not recommended. SMDPfier is designed as a single-level abstraction. For multi-level hierarchy, consider:</p> <ol> <li>Option composition: Create complex options from simple ones</li> <li>Custom option generators: Generate hierarchical option sets</li> <li>External hierarchy: Use SMDPfier as one level in a larger system</li> </ol> <p>Still have questions? Check the API Reference or examples for more details.</p>"},{"location":"masking_and_precheck/","title":"Masking and Precheck","text":"<p>SMDPfier provides sophisticated action masking and precheck validation to handle invalid options gracefully and ensure robust option execution.</p>"},{"location":"masking_and_precheck/#action-masking","title":"Action Masking","text":"<p>Action masking restricts which options are available based on the current environment state. This is essential for handling state-dependent action validity in complex environments.</p>"},{"location":"masking_and_precheck/#key-concepts","title":"Key Concepts","text":"<ul> <li>Availability Function: Determines which option indices are valid</li> <li>Action Mask: Binary array indicating available options  </li> <li>Index Interface Only: Masking only works with <code>action_interface=\"index\"</code></li> <li>Dynamic Evaluation: Mask is recomputed every step</li> </ul>"},{"location":"masking_and_precheck/#basic-action-masking","title":"Basic Action Masking","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import ConstantOptionDuration\n\n# Define options for CartPole\noptions = [\n    Option([0, 0], \"strong-left\"),      # Index 0\n    Option([1, 1], \"strong-right\"),     # Index 1  \n    Option([0, 1], \"left-right\"),       # Index 2\n    Option([1, 0], \"right-left\"),       # Index 3\n]\n\ndef cart_availability(obs):\n    \"\"\"Restrict options based on cart position and velocity.\"\"\"\n    position, velocity = obs[0], obs[1]\n\n    available = []\n\n    # Always allow balanced options\n    available.extend([2, 3])  # left-right, right-left\n\n    # Restrict strong movements based on position\n    if position &lt; 0.3:    # Cart not too far right\n        available.append(1)   # Allow strong-right\n    if position &gt; -0.3:   # Cart not too far left  \n        available.append(0)   # Allow strong-left\n\n    return available\n\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(5),\n    action_interface=\"index\",\n    max_options=4,\n    availability_fn=cart_availability\n)\n\nobs, info = env.reset()\nprint(f\"Available options: {info['smdp']['action_mask']}\")\n# Might show: [1, 1, 1, 1] (all available) or [0, 1, 1, 1] (strong-left masked)\n</code></pre>"},{"location":"masking_and_precheck/#action-mask-structure","title":"Action Mask Structure","text":"<p>The action mask is a binary list where <code>1</code> means available and <code>0</code> means masked:</p> <pre><code>action_mask = [1, 0, 1, 0]  # Options 0 and 2 available, 1 and 3 masked\n</code></pre> <p>Usage in RL algorithms:</p> <pre><code>obs, info = env.reset()\naction_mask = info[\"smdp\"][\"action_mask\"]\n\n# In your RL algorithm:\nif action_mask is not None:\n    # Mask invalid actions (set their Q-values to -inf)\n    masked_q_values = q_values.copy()\n    masked_q_values[action_mask == 0] = -float('inf')\n    action = np.argmax(masked_q_values)\nelse:\n    action = np.argmax(q_values)\n</code></pre>"},{"location":"masking_and_precheck/#complex-masking-examples","title":"Complex Masking Examples","text":""},{"location":"masking_and_precheck/#environment-specific-masking","title":"Environment-Specific Masking","text":"<pre><code>def taxi_availability(obs):\n    \"\"\"Taxi-v3 environment masking.\"\"\"\n    # Decode Taxi state\n    taxi_row, taxi_col, passenger_loc, destination = env.unwrapped.decode(obs)\n\n    available = []\n\n    # Movement actions (always available)\n    available.extend([0, 1, 2, 3])  # south, north, east, west\n\n    # Pickup action (only if passenger at taxi location)\n    if passenger_loc &lt; 4:  # Passenger not in taxi\n        passenger_coords = env.unwrapped.locs[passenger_loc]\n        if (taxi_row, taxi_col) == passenger_coords:\n            available.append(4)  # Allow pickup\n\n    # Dropoff action (only if passenger in taxi at destination)\n    if passenger_loc == 4:  # Passenger in taxi\n        destination_coords = env.unwrapped.locs[destination]\n        if (taxi_row, taxi_col) == destination_coords:\n            available.append(5)  # Allow dropoff\n\n    return available\n\n# Taxi options\ntaxi_options = [\n    Option([0], \"south\"),      # Index 0\n    Option([1], \"north\"),      # Index 1\n    Option([2], \"east\"),       # Index 2\n    Option([3], \"west\"),       # Index 3\n    Option([4], \"pickup\"),     # Index 4\n    Option([5], \"dropoff\"),    # Index 5\n]\n\ntaxi_env = SMDPfier(\n    gym.make(\"Taxi-v3\"),\n    options_provider=taxi_options,\n    duration_fn=ConstantOptionDuration(1),\n    action_interface=\"index\",\n    max_options=6,\n    availability_fn=taxi_availability\n)\n</code></pre>"},{"location":"masking_and_precheck/#state-dependent-option-length","title":"State-Dependent Option Length","text":"<pre><code>def adaptive_availability(obs):\n    \"\"\"Allow different option lengths based on state.\"\"\"\n    velocity = abs(obs[1])  # Cart velocity\n\n    if velocity &gt; 0.5:  # High velocity - need quick corrections\n        return [0, 1]   # Only single-action options\n    else:  # Low velocity - can use longer sequences\n        return [0, 1, 2, 3, 4]  # All options available\n\noptions = [\n    Option([0], \"quick-left\"),        # Index 0 - quick\n    Option([1], \"quick-right\"),       # Index 1 - quick  \n    Option([0, 0], \"double-left\"),    # Index 2 - longer\n    Option([1, 1], \"double-right\"),   # Index 3 - longer\n    Option([0, 1, 0], \"zigzag\"),      # Index 4 - longest\n]\n\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(3),\n    action_interface=\"index\",\n    max_options=5,\n    availability_fn=adaptive_availability\n)\n</code></pre>"},{"location":"masking_and_precheck/#dynamic-options-with-masking","title":"Dynamic Options with Masking","text":"<p>When using dynamic option generators, the <code>availability_fn</code> is automatically passed to restrict generated options:</p> <pre><code>from smdpfier.defaults.options import RandomStaticLen\n\ndef state_aware_generator(obs, info):\n    \"\"\"Generate options based on state, using availability info.\"\"\"\n    # Get action mask from info (passed automatically)\n    action_mask = info.get(\"action_mask\")\n\n    if action_mask is not None:\n        # Generate options only with available actions\n        available_actions = [i for i, avail in enumerate(action_mask) if avail]\n    else:\n        # No masking - use all actions\n        available_actions = list(range(info[\"action_space\"].n))\n\n    # Generate random options with available actions only\n    options = []\n    for i in range(5):\n        if available_actions:\n            actions = random.choices(available_actions, k=3)\n            options.append(Option(actions, f\"dynamic_{i}\"))\n\n    return options\n\ndef base_availability(obs):\n    \"\"\"Base availability function.\"\"\"\n    if obs[0] &gt; 0:  # Cart right\n        return [0]  # Only left action\n    else:\n        return [0, 1]  # Both actions\n\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=state_aware_generator,\n    duration_fn=ConstantOptionDuration(2),\n    action_interface=\"index\",\n    max_options=5,\n    availability_fn=base_availability  # Passed to generator automatically\n)\n</code></pre>"},{"location":"masking_and_precheck/#precheck-validation","title":"Precheck Validation","text":"<p>Precheck validation attempts to validate options before execution by testing their actions in the current environment state.</p>"},{"location":"masking_and_precheck/#enabling-precheck","title":"Enabling Precheck","text":"<pre><code>env = SMDPfier(\n    base_env,\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(5),\n    action_interface=\"index\", \n    precheck=True  # Enable precheck validation\n)\n</code></pre>"},{"location":"masking_and_precheck/#how-precheck-works","title":"How Precheck Works","text":"<ol> <li>Before executing an option, SMDPfier saves the environment state</li> <li>Tests each action in the option sequence</li> <li>Restores the environment state after testing</li> <li>Raises SMDPOptionValidationError if any action fails</li> <li>Proceeds with execution if all actions are valid</li> </ol>"},{"location":"masking_and_precheck/#precheck-example","title":"Precheck Example","text":"<pre><code>from smdpfier.errors import SMDPOptionValidationError\n\n# Option that might be invalid in some states\nrisky_option = Option([0, 1, 0, 1, 0], \"risky-sequence\")\n\ntry:\n    obs, reward, term, trunc, info = env.step(risky_option)\nexcept SMDPOptionValidationError as e:\n    print(f\"Option '{e.option_name}' failed precheck!\")\n    print(f\"Failed at step {e.failing_step_index}\")\n    print(f\"Action {e.action_repr} is invalid\")\n    print(f\"Environment state: {e.short_obs_summary}\")\n\n    # Handle the error (e.g., try a different option)\n    fallback_option = Option([0], \"safe-fallback\")\n    obs, reward, term, trunc, info = env.step(fallback_option)\n</code></pre>"},{"location":"masking_and_precheck/#precheck-limitations","title":"Precheck Limitations","text":"<p>\u26a0\ufe0f Important Limitations:</p> <ol> <li>Environment must support state save/restore (not all environments do)</li> <li>Performance overhead from testing each option</li> <li>May not catch all edge cases (e.g., stochastic environments)</li> <li>False positives possible in complex environments</li> </ol> <p>Recommendation: Use precheck during development and debugging, consider disabling in production for performance.</p>"},{"location":"masking_and_precheck/#precheck-vs-masking","title":"Precheck vs Masking","text":"Approach When to Use Pros Cons Action Masking Known invalid patterns Fast, reliable Requires domain knowledge Precheck Unknown failure modes Automatic detection Slower, may have false positives Both Maximum safety Comprehensive validation Higher complexity"},{"location":"masking_and_precheck/#best-practices","title":"Best Practices","text":""},{"location":"masking_and_precheck/#masking-strategy","title":"Masking Strategy","text":"<pre><code>def robust_availability(obs):\n    \"\"\"Comprehensive availability function.\"\"\"\n    available = []\n\n    # Conservative base set (always safe)\n    available.extend([0, 1])  # Basic actions\n\n    # Add options based on state confidence\n    confidence = compute_state_confidence(obs)\n\n    if confidence &gt; 0.8:\n        available.extend([2, 3])  # Medium complexity options\n\n    if confidence &gt; 0.9:\n        available.extend([4, 5, 6])  # High complexity options\n\n    return available\n</code></pre>"},{"location":"masking_and_precheck/#error-resilient-option-design","title":"Error-Resilient Option Design","text":"<pre><code># Design options to minimize failure probability\nsafe_options = [\n    Option([0], \"single-left\"),       # Minimal option - rarely fails\n    Option([1], \"single-right\"),      # Minimal option - rarely fails\n    Option([0, 1], \"balanced\"),       # Balanced - self-correcting\n]\n\n# Avoid overly long or extreme options  \nrisky_options = [\n    Option([0]*10, \"extreme-left\"),   # Long sequence - high failure risk\n    Option([1]*10, \"extreme-right\"),  # Long sequence - high failure risk\n]\n</code></pre>"},{"location":"masking_and_precheck/#integration-with-rl-algorithms","title":"Integration with RL Algorithms","text":"<pre><code>class MaskedDQNAgent:\n    def select_action(self, obs, info):\n        q_values = self.q_network(obs)\n\n        # Apply action mask if available\n        action_mask = info.get(\"smdp\", {}).get(\"action_mask\")\n        if action_mask is not None:\n            masked_q_values = q_values.copy()\n            masked_q_values[np.array(action_mask) == 0] = -float('inf')\n            return np.argmax(masked_q_values)\n        else:\n            return np.argmax(q_values)\n\n    def train(self, env):\n        obs, info = env.reset()\n\n        while True:\n            action = self.select_action(obs, info)\n\n            try:\n                obs, reward, term, trunc, info = env.step(action)\n                # ... training logic ...\n            except SMDPOptionValidationError:\n                # Handle validation failure\n                continue\n\n            if term or trunc:\n                break\n</code></pre>"},{"location":"masking_and_precheck/#debugging-masking-issues","title":"Debugging Masking Issues","text":""},{"location":"masking_and_precheck/#inspect-masking-behavior","title":"Inspect Masking Behavior","text":"<pre><code>def debug_masking(env, num_steps=10):\n    \"\"\"Debug action masking behavior.\"\"\"\n    obs, info = env.reset()\n\n    for step in range(num_steps):\n        mask = info.get(\"smdp\", {}).get(\"action_mask\", [])\n        available_actions = [i for i, avail in enumerate(mask) if avail == 1]\n\n        print(f\"Step {step}:\")\n        print(f\"  Observation: {obs[:3]}...\")  # First 3 elements\n        print(f\"  Action mask: {mask}\")\n        print(f\"  Available actions: {available_actions}\")\n\n        if available_actions:\n            action = random.choice(available_actions)\n            obs, reward, term, trunc, info = env.step(action)\n\n            if term or trunc:\n                break\n        else:\n            print(\"  No actions available!\")\n            break\n\ndebug_masking(env)\n</code></pre>"},{"location":"masking_and_precheck/#common-masking-issues","title":"Common Masking Issues","text":"<p>Issue: All actions masked <pre><code>def overly_restrictive_availability(obs):\n    if obs[0] &gt; 2.0:  # Impossible condition\n        return []  # No actions available!\n    return [0, 1]\n\n# Fix: Ensure at least one action is always available\ndef better_availability(obs):\n    available = [0]  # Always allow basic action\n    if obs[0] &lt; 2.0:\n        available.append(1)\n    return available\n</code></pre></p> <p>Issue: Inconsistent masking <pre><code>def inconsistent_availability(obs):\n    # Problem: Random masking\n    return random.choices([0, 1, 2], k=random.randint(1, 3))\n\n# Fix: Deterministic masking based on state\ndef consistent_availability(obs):\n    position = obs[0]\n    if position &gt; 0.5:\n        return [0, 2]  # Deterministic based on position\n    else:\n        return [1, 2]\n</code></pre></p>"},{"location":"masking_and_precheck/#summary","title":"Summary","text":"Feature Purpose Best For Action Masking Restrict invalid options State-dependent validity Precheck Test options before execution Unknown failure modes Combined Maximum robustness Critical applications <p>Key Takeaways: - Use masking for known patterns of invalid actions - Use precheck for unknown failure modes during development - Design options to minimize failure probability - Always ensure at least one action remains available</p> <p>Next: Error Handling | See Also: API Reference</p>"},{"location":"migration_0_2/","title":"Migration Guide: 0.1.x \u2192 0.2.0","text":"<p>This guide helps you upgrade from SMDPfier 0.1.x to 0.2.0, which introduces simplified time semantics as a breaking change.</p>"},{"location":"migration_0_2/#what-changed","title":"\ud83c\udfaf What Changed","text":""},{"location":"migration_0_2/#core-simplification","title":"Core Simplification","text":"<p>v0.2.0 removes duration complexity: - \u274c No more <code>duration_fn</code> parameter - \u274c No more <code>partial_duration_policy</code> parameter - \u274c No more <code>smdpfier.defaults.durations</code> module - \u2705 Simple rule: each primitive action = 1 tick - \u2705 Duration = k_exec (number of actions executed)</p>"},{"location":"migration_0_2/#info-structure-changes","title":"Info Structure Changes","text":"<pre><code># 0.1.x - Old info structure\ninfo[\"smdp\"] = {\n    \"duration_planned\": 10,\n    \"duration_exec\": 10,\n    \"time_units\": \"ticks\",\n    # ...\n}\n\n# 0.2.0 - New info structure\ninfo[\"smdp\"] = {\n    \"duration\": 3,  # Simply equals k_exec\n    # ...\n}\n</code></pre>"},{"location":"migration_0_2/#migration-steps","title":"\ud83d\udcdd Migration Steps","text":""},{"location":"migration_0_2/#step-1-remove-duration_fn-parameter","title":"Step 1: Remove <code>duration_fn</code> Parameter","text":"<p>Before (0.1.x): <pre><code>from smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import ConstantOptionDuration, ConstantActionDuration\n\n# With duration function\nsmdp_env = SMDPfier(\n    env,\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(10),  # \u274c Remove this\n    action_interface=\"index\",\n    max_options=len(options)\n)\n</code></pre></p> <p>After (0.2.0): <pre><code>from smdpfier import SMDPfier, Option\n\n# No duration function needed!\nsmdp_env = SMDPfier(\n    env,\n    options_provider=options,\n    action_interface=\"index\",\n    max_options=len(options)\n)\n</code></pre></p>"},{"location":"migration_0_2/#step-2-remove-duration-imports","title":"Step 2: Remove Duration Imports","text":"<p>Before (0.1.x): <pre><code>from smdpfier.defaults import (\n    ConstantOptionDuration,     # \u274c No longer exists\n    RandomOptionDuration,        # \u274c No longer exists\n    ConstantActionDuration,      # \u274c No longer exists\n    RandomActionDuration,        # \u274c No longer exists\n    MapActionDuration           # \u274c No longer exists\n)\n</code></pre></p> <p>After (0.2.0): <pre><code># No duration imports needed!\n# Duration is automatic: each action = 1 tick\n</code></pre></p>"},{"location":"migration_0_2/#step-3-update-info-access","title":"Step 3: Update Info Access","text":"<p>Before (0.1.x): <pre><code>obs, reward, term, trunc, info = env.step(action)\n\nduration_planned = info[\"smdp\"][\"duration_planned\"]  # \u274c No longer exists\nduration_exec = info[\"smdp\"][\"duration_exec\"]        # \u274c No longer exists\ntime_units = info[\"smdp\"][\"time_units\"]              # \u274c No longer exists\n</code></pre></p> <p>After (0.2.0): <pre><code>obs, reward, term, trunc, info = env.step(action)\n\nduration = info[\"smdp\"][\"duration\"]  # \u2705 Simple and clear\n# duration always equals k_exec\n</code></pre></p>"},{"location":"migration_0_2/#step-4-remove-partial_duration_policy","title":"Step 4: Remove <code>partial_duration_policy</code>","text":"<p>Before (0.1.x): <pre><code>smdp_env = SMDPfier(\n    env,\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(10),\n    partial_duration_policy=\"proportional\",  # \u274c Remove this\n)\n</code></pre></p> <p>After (0.2.0): <pre><code>smdp_env = SMDPfier(\n    env,\n    options_provider=options,\n    # No partial_duration_policy needed\n    # Early termination automatically handled: duration = k_exec\n)\n</code></pre></p>"},{"location":"migration_0_2/#common-migration-patterns","title":"\ud83d\udd04 Common Migration Patterns","text":""},{"location":"migration_0_2/#pattern-1-fixed-duration-per-option","title":"Pattern 1: Fixed Duration Per Option","text":"<p>Before (0.1.x): <pre><code>from smdpfier.defaults import ConstantOptionDuration\n\nenv = SMDPfier(\n    env,\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(10)\n)\n</code></pre></p> <p>After (0.2.0):</p> <p>If you want options to have consistent durations, make them the same length:</p> <pre><code># All options with 10 actions = 10 ticks each\noptions = [\n    Option([0] * 10, \"option-1\"),\n    Option([1, 0] * 5, \"option-2\"),  # 10 actions\n    Option([1] * 10, \"option-3\"),\n]\n\nenv = SMDPfier(env, options_provider=options)\n</code></pre>"},{"location":"migration_0_2/#pattern-2-fixed-duration-per-action","title":"Pattern 2: Fixed Duration Per Action","text":"<p>Before (0.1.x): <pre><code>from smdpfier.defaults import ConstantActionDuration\n\nenv = SMDPfier(\n    env,\n    options_provider=options,\n    duration_fn=ConstantActionDuration(1)  # Each action = 1 tick\n)\n</code></pre></p> <p>After (0.2.0):</p> <p>This is now the default! Each action automatically = 1 tick:</p> <pre><code># No change needed - this is automatic in 0.2.0\nenv = SMDPfier(env, options_provider=options)\n</code></pre>"},{"location":"migration_0_2/#pattern-3-variable-duration-per-option","title":"Pattern 3: Variable Duration Per Option","text":"<p>Before (0.1.x): <pre><code>from smdpfier.defaults import RandomOptionDuration\n\nenv = SMDPfier(\n    env,\n    options_provider=options,\n    duration_fn=RandomOptionDuration(min_duration=5, max_duration=15)\n)\n</code></pre></p> <p>After (0.2.0):</p> <p>Use variable-length options to get variable durations:</p> <pre><code>from smdpfier.defaults.options import RandomVarLen\n\n# Generate options with 5-15 actions = 5-15 ticks\nenv = SMDPfier(\n    env,\n    options_provider=RandomVarLen(\n        min_length=5,\n        max_length=15,\n        action_space_size=env.action_space.n,\n        num_options=10\n    ),\n    action_interface=\"index\",\n    max_options=10\n)\n</code></pre>"},{"location":"migration_0_2/#pattern-4-custom-time-modeling","title":"Pattern 4: Custom Time Modeling","text":"<p>Before (0.1.x): <pre><code>def custom_duration_fn(option, obs, info):\n    # Custom logic for duration\n    if option.name.startswith(\"fast\"):\n        return 5\n    else:\n        return 10\n\nenv = SMDPfier(env, options_provider=options, duration_fn=custom_duration_fn)\n</code></pre></p> <p>After (0.2.0):</p> <p>Option 1: Use option length to control duration: <pre><code>fast_options = [Option([0, 1] * 2, f\"fast-{i}\") for i in range(5)]  # 4 actions\nslow_options = [Option([0, 1] * 5, f\"slow-{i}\") for i in range(5)]  # 10 actions\n\nenv = SMDPfier(env, options_provider=fast_options + slow_options)\n</code></pre></p> <p>Option 2: Implement custom reward aggregator for time-aware rewards: <pre><code>def time_aware_rewards(rewards):\n    \"\"\"Penalize longer durations.\"\"\"\n    k = len(rewards)  # k_exec = duration\n    time_penalty = 0.1 * k\n    return sum(rewards) - time_penalty\n\nenv = SMDPfier(env, options_provider=options, reward_agg=time_aware_rewards)\n</code></pre></p>"},{"location":"migration_0_2/#smdp-discounting-updates","title":"\ud83e\uddee SMDP Discounting Updates","text":""},{"location":"migration_0_2/#before-01x","title":"Before (0.1.x)","text":"<pre><code>gamma = 0.99\n\nobs, reward, term, trunc, info = env.step(action)\nduration = info[\"smdp\"][\"duration_exec\"]  # Could differ from steps\n\n# Apply SMDP discount\ndiscounted = reward * (gamma ** duration)\n</code></pre>"},{"location":"migration_0_2/#after-020","title":"After (0.2.0)","text":"<pre><code>gamma = 0.99\n\nobs, reward, term, trunc, info = env.step(action)\nduration = info[\"smdp\"][\"duration\"]  # Always equals k_exec\n\n# Apply SMDP discount (same logic!)\ndiscounted = reward * (gamma ** duration)\n</code></pre>"},{"location":"migration_0_2/#breaking-changes-summary","title":"\u26a0\ufe0f Breaking Changes Summary","text":"Feature 0.1.x 0.2.0 Action Required <code>duration_fn</code> parameter Required Removed Delete parameter <code>partial_duration_policy</code> Optional Removed Delete parameter <code>time_units</code> attribute Always \"ticks\" Removed Remove references <code>info[\"smdp\"][\"duration_planned\"]</code> Available Removed Use <code>duration</code> <code>info[\"smdp\"][\"duration_exec\"]</code> Available Removed Use <code>duration</code> <code>info[\"smdp\"][\"time_units\"]</code> Always \"ticks\" Removed Remove references <code>smdpfier.defaults.durations</code> Module available Removed Remove imports"},{"location":"migration_0_2/#migration-checklist","title":"\u2705 Migration Checklist","text":"<ul> <li>[ ] Remove <code>duration_fn</code> parameter from all <code>SMDPfier()</code> calls</li> <li>[ ] Remove <code>partial_duration_policy</code> parameter if used</li> <li>[ ] Remove imports from <code>smdpfier.defaults.durations</code></li> <li>[ ] Replace <code>info[\"smdp\"][\"duration_exec\"]</code> with <code>info[\"smdp\"][\"duration\"]</code></li> <li>[ ] Replace <code>info[\"smdp\"][\"duration_planned\"]</code> with <code>info[\"smdp\"][\"duration\"]</code></li> <li>[ ] Remove <code>info[\"smdp\"][\"time_units\"]</code> references</li> <li>[ ] Adjust option lengths if you need specific durations</li> <li>[ ] Update tests to use new info structure</li> <li>[ ] Run tests to verify migration</li> </ul>"},{"location":"migration_0_2/#design-rationale","title":"\ud83c\udf93 Design Rationale","text":"<p>Why remove duration complexity?</p> <ol> <li>Simplicity: Each action = 1 tick is natural and intuitive</li> <li>Clarity: Duration = k_exec removes confusing \"steps vs ticks\" distinction  </li> <li>Flexibility: Option length already provides duration control</li> <li>Maintainability: Less code, fewer edge cases, cleaner API</li> <li>Focus: SMDP core is option-level decision making, not abstract time modeling</li> </ol> <p>What if I need custom time modeling?</p> <p>For most use cases, option length provides sufficient control. For advanced scenarios: - Use option length to control duration - Use reward aggregators for time-aware rewards - Implement custom wrapper if you need complex time semantics</p>"},{"location":"migration_0_2/#need-help","title":"\ud83c\udd98 Need Help?","text":"<ul> <li>Questions? Check the FAQ</li> <li>Bugs? Open an issue on GitHub</li> <li>Examples? See examples/</li> </ul> <p>Next: API Reference | Previous: Durations Guide</p>"},{"location":"usage_index_vs_direct/","title":"Index vs Direct Interfaces","text":"<p>SMDPfier provides two interfaces for option selection, each optimized for different use cases. Understanding when to use each interface is crucial for effective SMDP implementation.</p>"},{"location":"usage_index_vs_direct/#interface-comparison","title":"Interface Comparison","text":"Aspect Index Interface Direct Interface Action Space <code>Discrete(max_options)</code> Same as Option actions Actions Integer indices (0, 1, 2, ...) Option objects Best For Reinforcement Learning Scripting/Testing Action Masking Built-in support Not applicable Dynamic Options Supported with overflow handling Straightforward RL Integration Seamless Requires adaptation Debugging Index-based (less intuitive) Object-based (more intuitive)"},{"location":"usage_index_vs_direct/#index-interface","title":"Index Interface","text":"<p>The index interface transforms SMDPfier into a discrete action space where each action is an integer index selecting an available option.</p>"},{"location":"usage_index_vs_direct/#when-to-use-index-interface","title":"When to Use Index Interface","text":"<p>\u2705 Choose Index Interface When: - Training RL agents (most algorithms expect discrete actions) - Need action masking based on environment state - Working with dynamic option sets - Integrating with existing RL frameworks (Stable-Baselines3, RLLib, etc.) - Want built-in overflow handling for dynamic options</p>"},{"location":"usage_index_vs_direct/#basic-index-interface-setup","title":"Basic Index Interface Setup","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import ConstantOptionDuration\n\n# Define static options\noptions = [\n    Option([0, 0, 1], \"left-left-right\"),\n    Option([1, 1, 0], \"right-right-left\"),\n    Option([0, 1, 0], \"left-right-left\"),\n]\n\n# Create SMDPfier with index interface\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(5),\n    action_interface=\"index\",  # Default\n    max_options=len(options)   # Must specify for static options\n)\n\nprint(f\"Original action space: Discrete(2)\")\nprint(f\"SMDP action space: {env.action_space}\")  # Discrete(3)\n\n# Use integer actions\nobs, info = env.reset()\naction = 1  # Select second option (\"right-right-left\")\nobs, reward, term, trunc, info = env.step(action)\n\nprint(f\"Executed option: {info['smdp']['option']['name']}\")\n</code></pre>"},{"location":"usage_index_vs_direct/#action-masking-with-index-interface","title":"Action Masking with Index Interface","text":"<p>Action masking allows you to restrict which options are available based on the current environment state.</p> <pre><code>def cart_availability(obs):\n    \"\"\"Restrict options based on cart position.\"\"\"\n    cart_position = obs[0]\n\n    if cart_position &gt; 0.5:\n        return [0, 2]  # Only left-based options when cart is far right\n    elif cart_position &lt; -0.5:\n        return [1]     # Only right-based options when cart is far left\n    else:\n        return [0, 1, 2]  # All options available in center\n\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=options,\n    duration_fn=ConstantOptionDuration(5),\n    action_interface=\"index\",\n    max_options=3,\n    availability_fn=cart_availability\n)\n\nobs, info = env.reset()\nprint(f\"Available actions: {info['smdp']['action_mask']}\")\n# Might show: [1, 1, 1] (all available) or [1, 0, 1] (middle option masked)\n</code></pre>"},{"location":"usage_index_vs_direct/#dynamic-options-with-index-interface","title":"Dynamic Options with Index Interface","text":"<p>Dynamic options change based on the current state, requiring careful overflow handling.</p> <pre><code>from smdpfier.defaults.options import RandomStaticLen\n\ndef dynamic_options_generator(obs, info):\n    \"\"\"Generate different options based on cart velocity.\"\"\"\n    velocity = obs[1]\n\n    if abs(velocity) &gt; 0.1:  # Fast movement\n        # Short options for quick corrections\n        return [\n            Option([0], \"quick-left\"),\n            Option([1], \"quick-right\"),\n        ]\n    else:  # Slow movement  \n        # Longer options for building momentum\n        return [\n            Option([0, 0, 0], \"triple-left\"),\n            Option([1, 1, 1], \"triple-right\"),\n            Option([0, 1, 0], \"left-right-left\"),\n            Option([1, 0, 1], \"right-left-right\"),\n        ]\n\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=dynamic_options_generator,\n    duration_fn=ConstantOptionDuration(3),\n    action_interface=\"index\",\n    max_options=4  # Maximum expected options\n)\n\nobs, info = env.reset()\n# If generator returns 2 options but max_options=4:\n# - Actions 0,1 are valid\n# - Actions 2,3 are masked out\n# - info[\"smdp\"][\"action_mask\"] = [1, 1, 0, 0]\n</code></pre>"},{"location":"usage_index_vs_direct/#overflow-handling","title":"Overflow Handling","text":"<p>When dynamic options exceed <code>max_options</code>, SMDPfier applies truncate policy by default:</p> <pre><code># Generator returns 6 options, but max_options=4\navailable_options = dynamic_generator(obs, info)  # Returns 6 options\n# Result: First 4 options are used, 2 are dropped\n# info[\"smdp\"][\"num_dropped\"] = 2\n</code></pre>"},{"location":"usage_index_vs_direct/#direct-interface","title":"Direct Interface","text":"<p>The direct interface allows you to pass <code>Option</code> objects directly to <code>env.step()</code>, providing an intuitive and flexible approach.</p>"},{"location":"usage_index_vs_direct/#when-to-use-direct-interface","title":"When to Use Direct Interface","text":"<p>\u2705 Choose Direct Interface When: - Scripting or testing specific option sequences - Building non-RL controllers or heuristics - Debugging option behavior - Prototyping before RL training - Need full control over option selection</p>"},{"location":"usage_index_vs_direct/#basic-direct-interface-setup","title":"Basic Direct Interface Setup","text":"<pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import ConstantActionDuration\n\n# Define options\noptions = [\n    Option([0, 0, 1], \"left-left-right\"),\n    Option([1, 1, 0], \"right-right-left\"),\n    Option([0, 1, 0, 1], \"alternating\"),\n]\n\n# Create SMDPfier with direct interface\nenv = SMDPfier(\n    gym.make(\"CartPole-v1\"),\n    options_provider=options,\n    duration_fn=ConstantActionDuration(2),  # 2 ticks per action\n    action_interface=\"direct\"\n)\n\nprint(f\"Action space: {env.action_space}\")  # Same as original env\n\n# Use Option objects directly\nobs, info = env.reset()\noption = options[1]  # Select \"right-right-left\"\nobs, reward, term, trunc, info = env.step(option)\n\nprint(f\"Executed {info['smdp']['k_exec']} steps\")\nprint(f\"Duration: {info['smdp']['duration_exec']} ticks\")\n</code></pre>"},{"location":"usage_index_vs_direct/#dynamic-options-with-direct-interface","title":"Dynamic Options with Direct Interface","text":"<pre><code>def get_option_for_state(obs):\n    \"\"\"Select option based on current state.\"\"\"\n    cart_position, cart_velocity = obs[0], obs[1]\n\n    if cart_position &gt; 0 and cart_velocity &gt; 0:\n        return Option([0, 0], \"strong-left\")  # Moving right, correct strongly\n    elif cart_position &lt; 0 and cart_velocity &lt; 0:\n        return Option([1, 1], \"strong-right\")  # Moving left, correct strongly\n    else:\n        return Option([0, 1], \"gentle-correction\")  # Gentle correction\n\n# Simple control loop\nobs, info = env.reset()\nfor step in range(100):\n    option = get_option_for_state(obs)\n    obs, reward, term, trunc, info = env.step(option)\n\n    if term or trunc:\n        break\n</code></pre>"},{"location":"usage_index_vs_direct/#continuous-actions-with-direct-interface","title":"Continuous Actions with Direct Interface","text":"<p>The direct interface works seamlessly with continuous action spaces:</p> <pre><code>import gymnasium as gym\nfrom smdpfier import SMDPfier, Option\nfrom smdpfier.defaults import ConstantOptionDuration\n\n# Continuous action options\ncontinuous_options = [\n    Option([[-1.0], [0.0], [1.0]], \"left-center-right\"),\n    Option([[0.5], [0.5]], \"gentle-right\"),\n    Option([[-2.0]], \"hard-left\"),\n]\n\nenv = SMDPfier(\n    gym.make(\"Pendulum-v1\"),\n    options_provider=continuous_options,\n    duration_fn=ConstantOptionDuration(5),\n    action_interface=\"direct\"\n)\n\nobs, info = env.reset()\noption = continuous_options[0]\nobs, reward, term, trunc, info = env.step(option)\n</code></pre>"},{"location":"usage_index_vs_direct/#interface-selection-guide","title":"Interface Selection Guide","text":""},{"location":"usage_index_vs_direct/#choose-index-interface-when","title":"Choose Index Interface When:","text":"<pre><code># RL Training\nenv = SMDPfier(..., action_interface=\"index\", max_options=10)\nagent.learn(env)  # Works with any RL algorithm\n\n# Action Masking Needed\nenv = SMDPfier(..., action_interface=\"index\", availability_fn=mask_fn)\n\n# Dynamic Options with Overflow\nenv = SMDPfier(..., action_interface=\"index\", max_options=20)\n# Handles varying option counts gracefully\n</code></pre>"},{"location":"usage_index_vs_direct/#choose-direct-interface-when","title":"Choose Direct Interface When:","text":"<pre><code># Scripted Control\nfor situation in test_cases:\n    option = select_option_for_situation(situation)\n    obs, reward, term, trunc, info = env.step(option)\n\n# Debugging Specific Options\nproblem_option = Option([0, 1, 0], \"problematic-sequence\")\nobs, reward, term, trunc, info = env.step(problem_option)\n\n# Prototyping Before RL\ndef human_policy(obs):\n    return Option([best_action_for(obs)], \"human-choice\")\n</code></pre>"},{"location":"usage_index_vs_direct/#configuration-examples","title":"Configuration Examples","text":""},{"location":"usage_index_vs_direct/#index-interface-configuration","title":"Index Interface Configuration","text":"<pre><code># Static options with masking\nenv = SMDPfier(\n    base_env,\n    options_provider=static_options,\n    duration_fn=ConstantOptionDuration(10),\n    action_interface=\"index\",\n    max_options=len(static_options),\n    availability_fn=masking_function,\n    precheck=True  # Validate options before execution\n)\n\n# Dynamic options with overflow handling\nenv = SMDPfier(\n    base_env,\n    options_provider=dynamic_generator,\n    duration_fn=RandomActionDuration(2, 5),\n    action_interface=\"index\", \n    max_options=15,  # Allow up to 15 options\n    # Overflow: truncate to first 15, record num_dropped\n)\n</code></pre>"},{"location":"usage_index_vs_direct/#direct-interface-configuration","title":"Direct Interface Configuration","text":"<pre><code># Simple direct interface\nenv = SMDPfier(\n    base_env,\n    options_provider=option_list,\n    duration_fn=ConstantActionDuration(3),\n    action_interface=\"direct\"\n    # No max_options needed\n    # No availability_fn needed\n)\n</code></pre>"},{"location":"usage_index_vs_direct/#summary","title":"Summary","text":"Use Case Recommended Interface Why RL Training Index Discrete action space expected Action Masking Index Built-in masking support Dynamic Options Index Overflow handling Scripting/Testing Direct Intuitive option passing Debugging Direct Clear option identification Continuous Actions Direct Natural continuous support Prototyping Direct Flexible experimentation <p>Most Common Pattern: 1. Start with direct interface for prototyping and testing 2. Switch to index interface when training RL agents</p> <p>Next: Masking and Precheck | See Also: API Reference</p>"}]}